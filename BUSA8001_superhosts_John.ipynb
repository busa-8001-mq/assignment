{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a106c2-f185-492f-87bb-79286c2eacc4",
   "metadata": {},
   "source": [
    "### Business Analytics Group Assignment - Predicting Airbnb Listing Prices in Melbourne__ {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c316658-edf7-4797-b078-202987b4922b",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Kaggle Competition Ends:** Friday, 2 June 2023 @ 3:00pm (Week 13)  \n",
    "**Assignment Due Date on iLearn:** Friday, 2 June 2023 @ 11.59pm (Week 13)   \n",
    "\n",
    "**Overview:**   \n",
    "\n",
    "- In the group assignment you will form a team of 3 students and participate in a forecasting competition on Kaggle\n",
    "- The goal is to predict listed prices of Airbnb properties in Melbourne based on various Airbnb characteristics and regression models\n",
    "- Assessment Summary:  \n",
    "    - Write a problem statement and perform Exploratory Data Analysis  \n",
    "    - Clean up data, deal with categorical features and missing observations, and create new explanatory variables (feature engineering)  \n",
    "    - Construct and tune forecasting models, produce forecasts and submit your predictions to Kaggle  \n",
    "    - Each member of the team will record a video presentation of their work  \n",
    "    - Marks will be awarded producing a prediction in the top 5 positions of their unit as well as for reaching the highest ranking on Kaggle amongst all teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2270744-5e12-447b-a861-9719409e287c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Instructions:** \n",
    "\n",
    "- Form a team of 3 students (minimum 2 students)  \n",
    "- Each team member needs to join [https://www.kaggle.com](https://www.kaggle.com/)  \n",
    "- Choose a team leader and form a team in the competition [https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12](https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12)\n",
    "    - Team leader to click on `team` and join and invite other team members to join\n",
    "    - Your **team's name must start** with your unit code, for instance you could have a team called BUSA8001_masterful_geniuses or BUSA3020_l33t \n",
    "- All team members should work on all the tasks listed below however   \n",
    "    - Choose a team member who will be responsible for one of each of the 3 tasks listed below    \n",
    "- Your predictions must be generated by a model you develop here \n",
    "    - You will receive a mark of zero if your code provided here does not produce the forecasts you submit to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ee56b-c5b9-4078-8754-e04f90797514",
   "metadata": {},
   "source": [
    "**Marks**: \n",
    "\n",
    "- Total Marks: 40\n",
    "- Your individual mark will consist of:  \n",
    "    - 50% x overall assignment mark + 45% x mark for the task that you are responsible for + 5% x mark received from your teammates for your effort in group work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f70e4c-b794-4555-b170-d80b628b2904",
   "metadata": {},
   "source": [
    "**Competition Marks:**  \n",
    "\n",
    "- 1 mark: Ranking in the top 5 places of your unit on Kaggle (make sure you name your team as instructed above)   \n",
    "- 2 marks: Reaching the first place in your unit (make sure you name your team as instructed above)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3180e9-c3cc-494c-ae64-d3b9701e10e8",
   "metadata": {},
   "source": [
    "\n",
    "**Submissions:**  \n",
    "\n",
    "1. On Kaggle: submit your team's forecast in order to be ranked by Kaggle\n",
    "    - Can do this as many times as necessary while building their model  \n",
    "2. On iLearn **only team leader to submit** this Jupyter notebook re-named `Group_Assignment_Team_Name.ipynb` where Team_Name is your team's name on Kaggle   \n",
    "    - The Jupyter notebook must contain team members names/ID numbers, and team name in the competition\n",
    "    - Provide answers to the 3 Tasks below in the allocated cells including all codes/outputs/writeups \n",
    "    - One 15 minute video recording of your work \n",
    "        - Each team member to provide a 5 minute presentation of the Task that they led (it is best to jointly record your video using Zoom)\n",
    "        - When recording your video make sure your face is visible, that you share your Jupyter Notebook and explain everything you've done in the submitted Jupyter notebook on screen\n",
    "        - 5 marks will be deducted from each Task for which there is no video presentation or if you don't follow the above instructions\n",
    "        \n",
    "3. On iLearn each student needs to submit a file with their teammates' names, ID number and a mark for their group effort (out of 100%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbce8a-bf4f-4155-9336-6367fd239f6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe68a60-5e8b-4c4e-b562-3a82fa426395",
   "metadata": {},
   "source": [
    "**Fill out the following information**\n",
    "\n",
    "For each team member provide name, Student ID number and which task is performed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac487d3-755a-4a69-a22f-d599dbdd7979",
   "metadata": {},
   "source": [
    "- Team Name on Kaggle: `BUSA8001_superhosts`\n",
    "- Team Leader and Team Member 1: `Felix Rosenberger`\n",
    "- Team Member 2: `John Rizk`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24de689-928d-4991-b337-760c12780e5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Problem Description and Initial Data Analysis {-}\n",
    "\n",
    "1. Read the Competition Overview on Kaggle [https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12](https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12)\n",
    "2. Referring to Competition Overview and the data provided on Kaggle write about a 500 words **Problem Description** focusing on key points that will need to be addressed as first steps in Tasks 2 and 3 below, using the following headings:\n",
    "    - Forecasting Problem - explain what you are trying to do and how it could be used in the real world (i.e. why it may be important)\n",
    "    - Evaluation Criteria - explain the criteria is used to assess forecast performance \n",
    "    - Types of Variables/Features\n",
    "    - Data summary and main data characteristics\n",
    "    - Missing Values (only explain what you found at this stage)\n",
    "    - Hint: you should **not** discuss any specific predictive algorithms at this stage\n",
    "    - Note: This task should be completed in a single Markdown cell (text box)\n",
    "    \n",
    "Total Marks: 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dcfd49e-fcbb-4eaa-936b-144b574495d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 1 code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# setting display options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "# read in data\n",
    "trainpath = \"train.csv\"\n",
    "df_train = pd.read_csv(trainpath, index_col='ID')\n",
    "testpath = \"test.csv\"\n",
    "df_test = pd.read_csv(testpath, index_col='ID')\n",
    "\n",
    "# concatenate dataframes to reduce redundancies in operations\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "#df.head()\n",
    "#test_ids = df.ID.iloc[7000:].values\n",
    "df.to_csv(\"df_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11781cdd-1178-4318-bdea-ca49b793e06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data summary and characteristics\n",
    "df['price'].describe()\n",
    "df.info()\n",
    "df.dtypes.value_counts().to_frame()\n",
    "#print(len(df.columns))\n",
    "# types of variables / features\n",
    "#vtypes = df.dtypes.to_frame()\n",
    "#vtypes.value_counts()\n",
    "#vtypes\n",
    "\n",
    "#print(df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97567b7a-cdaf-4858-be7d-b1c4ba55f389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test])\n",
    "df['price'] = df.price.str.replace('$', '', regex=True).str.replace(',', '', regex=True).astype('float')\n",
    "d = df.groupby('neighbourhood_cleansed')['price'].describe().round(2)\n",
    "#d = df.groupby(['property_type','bathrooms'])['price'].describe().round(2)\n",
    "\n",
    "#d = df.groupby('property_type')['price'].mean().dropna().round(2)\n",
    "d.sort_values(by=['mean'], inplace=True, ascending=False)\n",
    "#d.sort_values(by=['count'], inplace=True, ascending=False)\n",
    "d\n",
    "#df['price']\n",
    "print(min(df['price']))\n",
    "print(max(df['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3baa31-9b95-4d1d-9fb1-b9a7a47f7bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_values_count_train = pd.DataFrame(df_train.isnull().sum(axis=0)).loc[df_train.isnull().sum(axis=0) != 0]\n",
    "\n",
    "missing_values_count_test = pd.DataFrame(df_test.isnull().sum(axis=0)).loc[df_test.isnull().sum(axis=0) != 0]\n",
    "\n",
    "missing_values_count = pd.merge(missing_values_count_train, missing_values_count_test, how='outer', left_index=True, right_index=True)\n",
    "missing_values_count.fillna(0, inplace=True)\n",
    "missing_values_count = missing_values_count.rename(columns={'0_x': 'missing_train', '0_y': 'missing_test'})\n",
    "missing_values_count['total_missing'] = missing_values_count['missing_train'] + missing_values_count['missing_test']\n",
    "\n",
    "print('Total Missing records = ', sum(missing_values_count['total_missing']))\n",
    "\n",
    "missing_values_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960bb55-92da-4528-9ee1-e06e46f00cae",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>Forecasting Problem</font>\n",
    "<font color='darkblue'>\n",
    "Aiirbnb is an \"online marketplace that connects people who want to rent out their homes with people who are looking for accommodations in specific locales.\" https://www.investopedia.com/articles/personal-finance/032814/pros-and-cons-using-airbnb.asp\n",
    "\n",
    "The goal of is this assignment is to develop a model for predicting nightly prices of Melbournd based Airbnb listings with different features and characteristics based on statistical machine learning. The model can be used to assess the how rental prices differ based on specific characteristics of the property or against other suburbs, which can then be used to determine the profitability and feasibilty of certain listings. \n",
    "\n",
    "### Evaluation Criteria\n",
    "The criteria to assess prediction performance is RMSE. This performance metric measures the average distance between predictions obtained by a model and actual target values. Thus, the lower the distance (and the smaller RMSE), the better the prediction quality. It also has the advantage of being in the same unit as the predicted variable which makes it easy to interpret.\n",
    "\n",
    "### Variables / Features\n",
    "\n",
    "The data consists of 60 columns, 27 of type object, 18 of type float64 and 15 of type int64 types.\n",
    "<br>\n",
    "<br>\n",
    "The variables types were classified into the following data types, 21 nominal, 12 ordinal and 27 numeric.\n",
    "\n",
    "\n",
    "### Data Summary and Main Characteristics\n",
    "\n",
    "Evaluation of the prices suggest that the distribution of prices is skewed with the range of prices between <b>25</b> and <b>145160</b> with a mean of <b>285.65</b>.\n",
    "\n",
    "Prices appear to be sensitive to property type, with <b>Private room in villa</b> having the highest mean price of <b>2358.36</b> by <b>property type</b>, which is much higher than the mean prices of other property types, suggesting that the distribution of prices for this property type may be highly skewed. <b>Private room in bungalow</b> has the lowest mean price of <b>64.11</b>. \n",
    "\n",
    "<b>Entire rental unit</b> have the highest listings <b>2984</b>, and a mean price of <b>296.87</b>, which is close to the overall mean price, while <b>Shared room in guesthouse</b> has the least listings <b>2</b>, and a mean price of <b>67.00</b>.\n",
    "\n",
    "<b>Boroondara</b> has the highest mean price of <b>894.95</b> by <b>neighbourhood_cleansed</b> and <b>Greater Dandenong</b> has the lowest mean price of <b>115.41</b>. Prices also seem sensitive to neighbourhood_cleansed. <b>Melbourne</b> has the highest listing of <b>2062</b>, and mean price of <b>335.35</b>, and <b>Greater Dandenong</b> has the lowest lisitngs of<b>32</b>.\n",
    "\n",
    "<b>Instant bookable</b> properties have a slighly higher mean price <b>298.96</b> compared with those that are not instant bookable <b>281.34</b>.\n",
    "\n",
    "<b>Entire home/apt</b> have the highest listing <b>by room type</b> with a mean price of <b>312.19</b>. <b>Hotel room</b> and <b>Shared room</b> have the least lisitings with a combined total of <b>80</b>.\n",
    "\n",
    "Prices increase as the number of <b>accomodates</b> increases from 1 to 16, ranging from a mean of <b>81.65</b> to <b>724.04</b>. \n",
    "\n",
    "Intial review of the features indicates that price dependant variables may include:\n",
    "<br>&nbsp;&nbsp;room_type (nominal)\n",
    "<br>&nbsp;&nbsp;neighbourhood_cleansed (nominal)\n",
    "<br>&nbsp;&nbsp;accommodates (numeric)\n",
    "<br>&nbsp;&nbsp;bathrooms (numeric)\n",
    "<br>&nbsp;&nbsp;bedrooms (numeric)\n",
    "<br>&nbsp;&nbsp;beds (numeric)\n",
    "<br>&nbsp;&nbsp;amenities (nominal)\n",
    "<br>&nbsp;&nbsp;review_scores_rating (ordinal)\n",
    "<br>&nbsp;&nbsp;instant_bookable (nominal)\n",
    "\n",
    "### Missing Observation\n",
    "\n",
    "There are 24202 missing values across 29 variables, spread fairly evenly between the train and data sets.\n",
    "</font>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30df24-b18b-4f61-975f-ceebe2e2c3ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Data Cleaning, Missing Observations and Feature Engineering {-}\n",
    "- In this task you will follow a set of instructions/questions listed below.\n",
    "- Make sure you **explain** each step you do both in Markdown text and on your video.\n",
    "    - Do not just read out your commands without explaining what they do and why you used them \n",
    "\n",
    "Total Marks: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d3f63-c3e3-4661-9cc1-a2bec6acc397",
   "metadata": {},
   "source": [
    "**Task 2, Question 1**: Clean **all** numerical features and the target variable `price` so that they can be used in training algorithms. For instance, `host_response_rate` feature is in object format containing both numerical values and text. Extract numerical values (or equivalently eliminate the text) so that the numerical values can be used as a regular feature.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cbddc92-8165-4c44-9373-edfadd507d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "#Functions\n",
    "def replace_string(df, c, s, r='', f='strip'):\n",
    "    if f == 'find_replace':\n",
    "        mask = (df[c].notnull()) & (df[c].astype(str).str.contains(s))\n",
    "        df.loc[mask, c] = df.loc[mask, c].astype(str).str.replace(s, r)\n",
    "    if f == 'replace':\n",
    "        df[c] = df[c].replace(s, r)\n",
    "    elif f == 'strip':\n",
    "        df[c] = df[c].dropna().astype(str).str.replace(s, r, regex=True)\n",
    "    return df\n",
    "\n",
    "def replace_numeric(df, c, n, r=0, f='match'):\n",
    "    if f == 'isgreater':\n",
    "        df.loc[df[c] > n, c] = r\n",
    "    elif f == 'isless':\n",
    "        df.loc[df[c] < n, c] = r\n",
    "    elif f == 'match':\n",
    "        df.loc[df[c] == n, c] = r\n",
    "    return df\n",
    "\n",
    "def convert_numeric(df, c, t, d=1):\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df[c] = df[c].astype(t)\n",
    "    df[c] = df[c] / d\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845e482a-a3fa-4867-9f56-8e28311332bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df\n",
    "\n",
    "# price\n",
    "df2 = replace_string(df2, 'price', '$','', 'strip')\n",
    "df2 = replace_string(df2, 'price', ',','', 'strip')\n",
    "df2 = convert_numeric(df2, 'price', 'float', 1)\n",
    "\n",
    "# host_response_rate\n",
    "df2 = replace_string(df2, 'host_response_rate', '%','', 'strip')\n",
    "df2 = convert_numeric(df2, 'host_response_rate', 'float', 100)\n",
    "\n",
    "# host_acceptance_rate\n",
    "df2 = replace_string(df2, 'host_acceptance_rate', '%','', 'strip')\n",
    "df2 = convert_numeric(df2, 'host_acceptance_rate', 'float', 100)\n",
    "\n",
    "# bathrooms\n",
    "df2 = replace_string(df2, 'bathrooms', 'Half-bath','0.5', 'find_replace')\n",
    "df2 = replace_string(df2, 'bathrooms', 'half-bath','0.5', 'find_replace')\n",
    "df2 = replace_string(df2, 'bathrooms', '[^0-9\\.]','', 'strip')\n",
    "df2 = convert_numeric(df2, 'bathrooms', 'float', 1)\n",
    "\n",
    "# max/min nights - replace extreme values\n",
    "df2 = replace_numeric(df2, 'maximum_nights', 9000, 1000, 'isgreater')\n",
    "df2 = replace_numeric(df2, 'minimum_maximum_nights', 9000, 1000, 'isgreater')\n",
    "df2 = replace_numeric(df2, 'maximum_maximum_nights', 9000, 1000, 'isgreater')\n",
    "df2 = replace_numeric(df2, 'minimum_nights_avg_ntm', 9000, 1000, 'isgreater')\n",
    "df2 = replace_numeric(df2, 'maximum_nights_avg_ntm', 9000, 1000, 'isgreater')\n",
    "\n",
    "df2.to_csv(\"df_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339a5e8-1595-4d27-87f5-7f8cf02caa5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <font color='darkblue'>price Problem</font>\n",
    "<font color='darkblue'>\n",
    "The target variable price was converted from a string containing the $ sign to a numeric float variable.\n",
    "<br>\n",
    "    \n",
    "#### <font color='darkblue'>host_response_rate and host_acceptance_rate</font>    \n",
    "host_response_rate and host_acceptance_rate variables were converted from strings containing the % sign to a numeric float variable.\n",
    "<br>\n",
    "\n",
    "#### <font color='darkblue'>bathrooms</font>\n",
    "Some records for bathrooms were 'Half-bath' and 'half-bath', that is they did not contain any numeric characters. These were converted to the string '0.5'. For the remaining records non-numeric characters were removed and then the whole column was converted to a numeric float variable.\n",
    "<br>\n",
    "\n",
    "#### <font color='darkblue'>maximum_nights, minimum_maximum_nights,maximum_maximum_nights and maximum_nights_avg_ntm</font>    \n",
    "maximum_nights, minimum_maximum_nights,maximum_maximum_nights and maximum_nights_avg_ntm had some extreme values, which appear to be in error - these were replaced with 1000 which appears to be the threshold based on other min/max nights variables.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f279e05-fbfd-4286-a6e1-57ce4454be3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f1bb1",
   "metadata": {},
   "source": [
    "**Task 2, Question 2** Create at least 4 new features from existing features which contain multiple items of information, e.g. creating `email`,  `phone`, `work_email`, etc. from feature `host_verifications`.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31fd9681-9b74-4a12-bf4c-92a11328c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2\n",
    "\n",
    "# Create new features email, phone and work_email from host_verifications\n",
    "df3 = replace_string(df3, 'host_verifications', \"['email']\",\"'1','0','0'\", 'replace')\n",
    "df3 = replace_string(df3, 'host_verifications', \"['phone']\",\"'0','1','0'\", 'replace')\n",
    "df3 = replace_string(df3, 'host_verifications', \"['email', 'phone']\",\"'1','1','0'\", 'replace')\n",
    "df3 = replace_string(df3, 'host_verifications', \"['phone', 'work_email']\",\"'0','1','1'\", 'replace')\n",
    "df3 = replace_string(df3, 'host_verifications', \"['email', 'phone', 'work_email']\",\"'1','1','1'\", 'replace')\n",
    "\n",
    "df3[['email', 'phone', 'work_email']] = df3['host_verifications'].str.split(',', expand=True)\n",
    "\n",
    "df3 = replace_string(df3, 'email', \"'\",'', 'strip')\n",
    "df3 = convert_numeric(df3, 'email','int', 1)\n",
    "\n",
    "df3 = replace_string(df3, 'phone', \"'\",'', 'strip')\n",
    "df3 = convert_numeric(df3, 'phone','int', 1)\n",
    "\n",
    "df3 = replace_string(df3, 'work_email', \"'\",'', 'strip')\n",
    "df3 = convert_numeric(df3, 'work_email','int', 1)\n",
    "\n",
    "df3.drop(['host_verifications'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75f66cdd-4588-484a-aac7-e9feb3faf197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new features smoke_alarm, kitchen, essential, hangers, wifi from amenities\n",
    "# These are the top 5 ammenities in the dataset\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "amenity_count = Counter()\n",
    "amenity_count_total = Counter()\n",
    "count_total = []\n",
    "\n",
    "for amenities_str in df3['amenities']:\n",
    "    amenity_count_total = 0\n",
    "    amenities_list = amenities_str.strip('][').replace('\"', '').split(', ')\n",
    "    for amenity in amenities_list:\n",
    "        amenity_count[amenity] += 1\n",
    "        amenity_count_total  += 1\n",
    "    count_total.append(amenity_count_total)\n",
    "\n",
    "df_amenities = pd.DataFrame(columns=[ 'amenity_count'])\n",
    "df_amenities['amenity_count'] = amenity_count\n",
    "df_amenities = df_amenities.sort_values('amenity_count', ascending=False)\n",
    "df_amenities.head(5)\n",
    "\n",
    "#df_acc = pd.DataFrame(columns=[ 'total_amenity_counts'])\n",
    "#df_acc['total_amenity_counts'] = count_total\n",
    "#df_acc\n",
    "#print(acc)\n",
    "\n",
    "#Smoke alarm\t9548\n",
    "#Kitchen\t9383\n",
    "#Essentials\t9327\n",
    "#Hangers\t8702\n",
    "#Wifi\t8618\n",
    "\n",
    "df3['amenity_count'] = count_total\n",
    "\n",
    "df3[['smoke_alarm','kitchen','essentials','hangers','wifi']] = 0\n",
    "\n",
    "for idx, amenities_str in df3['amenities'].items():\n",
    "    amenities_list = amenities_str.strip('][').replace('\"', '').split(', ')\n",
    "    if 'Smoke alarm' in amenities_list:\n",
    "        df3.loc[idx, 'smoke_alarm'] = 1\n",
    "    if 'Kitchen' in amenities_list:\n",
    "        df3.loc[idx, 'kitchen'] = 1        \n",
    "    if 'Essentials' in amenities_list:\n",
    "        df3.loc[idx, 'essentials'] = 1      \n",
    "    if 'Hangers' in amenities_list:\n",
    "        df3.loc[idx, 'hangers'] = 1      \n",
    "    if 'Wifi' in amenities_list:\n",
    "        df3.loc[idx, 'wifi'] = 1              \n",
    "\n",
    "\n",
    "#df3.drop(['amenities'], axis=1, inplace=True) # needed in Felix notebook to calculate sum of amenities\n",
    "\n",
    "df3\n",
    "\n",
    "df3.to_csv(\"df_3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fde9b6-bed0-4018-9edb-3553f3d1fa13",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>New Features</font>\n",
    "<font color='darkblue'>\n",
    "\n",
    "#### <font color='darkblue'>host_verifications</font>    \n",
    "Created new binary numeric features 'email', 'phone', 'work_email from 'host_verifications' and deleted the column 'host_verifications'\n",
    "<br>\n",
    "    \n",
    "#### <font color='darkblue'>amenities</font>    \n",
    "Create new binary numeric features 'smoke_alarm', 'kitchen', 'essential', 'hangers', 'wifi' from 'amenities' which are the top 5 amenities in the dataset and deleted the column 'amenities'.\n",
    "<br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01c4d-1412-4e51-8f80-7040f536b1c7",
   "metadata": {},
   "source": [
    "**Task 2, Question 3**: Impute missing values for all features in both training and test datasets. Hint: make sure you do **not** impute the price in the test dataset.\n",
    "(3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36412d68-f68f-4764-aa6f-88ba33116ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def impute_missing(df, c, s='most_frequent'):\n",
    "    for col in c:\n",
    "        i = SimpleImputer(missing_values = np.nan, strategy=s) \n",
    "        i = i.fit(df[[col]])\n",
    "        df[[col]] = i.transform(df[[col]])\n",
    "    return df\n",
    "\n",
    "# host_location-> most_frequent\n",
    "df4 = impute_missing(df4, ['host_location'], 'most_frequent')\n",
    "\n",
    "# host_response_time -> most_frequent\n",
    "df4 = impute_missing(df4, ['host_response_time'], 'most_frequent')\n",
    "\n",
    "# host_response_rate, host_acceptance_rate -> mean\n",
    "df4 = impute_missing(df4, ['host_response_rate', 'host_acceptance_rate'], 'mean')\n",
    "\n",
    "# host_is_superhost -> most_frequent\n",
    "df4 = impute_missing(df4, ['host_is_superhost'], 'most_frequent')\n",
    "\n",
    "# host_neighbourhood, neighbourhood, neighbourhood_cleansed -> most_frequent\n",
    "df4 = impute_missing(df4, ['host_neighbourhood', 'neighbourhood', 'neighbourhood_cleansed'], 'most_frequent')\n",
    "\n",
    "# property_type, room_type -> most_frequent\n",
    "df4 = impute_missing(df4, ['property_type', 'room_type'], 'most_frequent')\n",
    "\n",
    "# bathrooms, bedrooms, beds, first_review -> median\n",
    "df4 = impute_missing(df4, ['bathrooms','bedrooms','beds'], 'median')\n",
    "\n",
    "# minimum_minimum_nights, maximum_maximum_nights -> median\n",
    "df4 = impute_missing(df4, ['minimum_minimum_nights', 'maximum_maximum_nights'], 'median')\n",
    "\n",
    "# availability_365 -> mean\n",
    "df4 = impute_missing(df4, ['availability_365'], 'mean')\n",
    "\n",
    "# first_review, last_review -> most_frequent\n",
    "df4 = impute_missing(df4, ['first_review', 'last_review'], 'most_frequent')\n",
    "\n",
    "#review_scores_accuracy, review_scores_checkin, review_scores_cleanliness, review_scores_communication, review_scores_location\n",
    "# review_scores_rating, review_scores_value -> mean\n",
    "df4 = impute_missing(df4, ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness','review_scores_checkin',\n",
    "                           'review_scores_communication', 'review_scores_location','review_scores_value'], 'mean')\n",
    "# reviews_per_month -> mean\n",
    "df4 = impute_missing(df4, ['reviews_per_month'], 'mean')\n",
    "\n",
    "# email, phone, work_email from -> most_frequent\n",
    "df4 = impute_missing(df4, ['email', 'phone', 'work_email'], 'most_frequent')\n",
    "\n",
    "# smoke_alarm, kitchen, essentials, hangers, wifi -> most_frequent\n",
    "df4 = impute_missing(df4, ['smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi'], 'most_frequent')\n",
    "\n",
    "#df4\n",
    "\n",
    "df4.to_csv(\"df_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb16b1d-f4f1-438e-a5af-ae9cc3c04467",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>Imputing missing values</font>\n",
    "<font color='darkblue'>\n",
    "<br>\n",
    "Imputed missing values for all features except for 'description', 'neighborhood_overview', 'host_location' and 'host_about'.\n",
    "<br>\n",
    "<br>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c14ab6-aff9-4fcd-ab7b-34f0b77f8caa",
   "metadata": {},
   "source": [
    "**Task 2, Question 4**: Encode all categorical variables appropriately as discussed in class. \n",
    "\n",
    "\n",
    "Where a categorical feature contains more than 5 unique values, map the feature into 5 most frequent values + 'other' and then encode appropriately. For instance, you could group then map `property_type` into 5 most frequent property types + 'other'  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f4448-8574-4397-a636-d83bbde885e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot encoder function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f56316-1963-44ca-90b8-183973807fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5 = df4\n",
    "\n",
    "\n",
    "#onehot encoder function\n",
    "def onehot(df, c):\n",
    "    for col in c:\n",
    "        df = df.join(pd.get_dummies(df[[col]], drop_first=True))\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#encode binary classifiers\n",
    "# 'host_is_superhost','host_has_profile_pic','host_identity_verified','has_availability','instant_bookable'\n",
    "df5 = onehot(df5, ['source', 'host_is_superhost','host_has_profile_pic','host_identity_verified','has_availability','instant_bookable'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#encode source\n",
    "#le = encoder.fit_transform(df5['source'].values)\n",
    "#df5['source'] = le\n",
    "#print('source:', encoder.classes_)\n",
    "\n",
    "#encode room_type\n",
    "le = encoder.fit_transform(df5['room_type'].values)\n",
    "df5['room_type'] = le\n",
    "room_type_classes = encoder.classes_\n",
    "\n",
    "\n",
    "#encode top 5 property_type and other\n",
    "top_5_property_type = df5['property_type'].value_counts().nlargest(5).index.tolist()  \n",
    "encoder.fit(top_5_property_type + ['other'])  \n",
    "#df5['property_type_encoded'] = df5['property_type'].apply(lambda x: x if x in top_5_property_type else 'other')\n",
    "df5['property_type'] = df5['property_type'].apply(lambda x: x if x in top_5_property_type else 'other')\n",
    "df5 = onehot(df5, ['property_type'])\n",
    "\n",
    "#df5['property_type_encoded'] = encoder.transform(df5['property_type'].apply(lambda x: x if x in top_5_property_type else 'other'))\n",
    "#df5.drop(['property_type'], axis=1, inplace=True)\n",
    "#df5 = df5.rename(columns={'property_type_encoded': 'property_type'})\n",
    "#property_type_classes = encoder.classes_\n",
    "\n",
    "\n",
    "#encode top 5 neighbourhood_cleansed and other\n",
    "top_5_neighbourhood_cleansed = df5['neighbourhood_cleansed'].value_counts().nlargest(5).index.tolist()  \n",
    "encoder.fit(top_5_neighbourhood_cleansed + ['other'])  \n",
    "df5['neighbourhood_cleansed_encoded'] = encoder.transform(df5['neighbourhood_cleansed'].apply(lambda x: x if x in top_5_neighbourhood_cleansed else 'other'))\n",
    "df5.drop(['neighbourhood_cleansed'], axis=1, inplace=True)\n",
    "df5 = df5.rename(columns={'neighbourhood_cleansed_encoded': 'neighbourhood_cleansed'})\n",
    "neighbourhood_cleansed_classes = encoder.classes_\n",
    "\n",
    "\n",
    "# map/rank host_response_time\n",
    "host_response_mapping = {'within an hour':1, 'within a few hours':2, 'within a day':3, 'a few days or more':4}\n",
    "df5['host_response_time'] = df5['host_response_time'].map(host_response_mapping)\n",
    "\n",
    "# convert host_since into days based on current date\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "df5['host_since'] = pd.to_datetime(df5['host_since'], format='%Y/%m/%d')\n",
    "df5['host_since'] = (today - df5['host_since']).dt.days\n",
    "\n",
    "#df5\n",
    "\n",
    "df5.to_csv(\"df_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad3f20-7549-4b9e-8894-818c976d1457",
   "metadata": {},
   "source": [
    "<font color='darkblue'>\n",
    "\n",
    "* Encoded  binray classifications \n",
    "<br>\n",
    "'source', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable' using onehot encoding.\n",
    "<br>\n",
    "<br>\n",
    "* Encoded 'room_type' using LabelEncoder.\n",
    "<br>\n",
    "<br>\n",
    "* Encoded 'property_type' and 'neighbourhood_cleansed' using LabelEncoder grouped by the top 5 classifications in each and the rese grouped as 'other'\n",
    "<br>\n",
    "<br>\n",
    "* Encoded and ranked host_response_time.\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d695347",
   "metadata": {},
   "source": [
    "**Task 2, Question 5**: Perform any other actions you think need to be done on the data before constructing predictive models, and clearly explain what you have done.   \n",
    "(1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7584f26-77fc-4bba-8202-5357a1565ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df6 = df5\n",
    "df6['log_price'] = np.log(df6['price'])\n",
    "\n",
    "df6.to_csv(\"df_6.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff3c3e7f-c666-43a0-98de-73fac6dfc4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>amenities</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>price</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>work_email</th>\n",
       "      <th>amenity_count</th>\n",
       "      <th>smoke_alarm</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>essentials</th>\n",
       "      <th>hangers</th>\n",
       "      <th>wifi</th>\n",
       "      <th>source_previous scrape</th>\n",
       "      <th>host_is_superhost_t</th>\n",
       "      <th>host_has_profile_pic_t</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>has_availability_t</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "      <th>property_type_Entire home</th>\n",
       "      <th>property_type_Entire rental unit</th>\n",
       "      <th>property_type_Private room in home</th>\n",
       "      <th>property_type_Private room in rental unit</th>\n",
       "      <th>property_type_other</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Stables, Richmond</td>\n",
       "      <td>Superbly located hotel style accommodation in ...</td>\n",
       "      <td>Richmond is a great neighbourhood.  A beautifu...</td>\n",
       "      <td>Ione</td>\n",
       "      <td>3721</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>I'm a working mum who loves being able to shar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Richmond, Victoria, Australia</td>\n",
       "      <td>-37.82030</td>\n",
       "      <td>144.99016</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Sukin conditioner\", \"Extra pillows and blank...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>741</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>4.940000</td>\n",
       "      <td>4.93000</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>4.820000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.882802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Room in Cool Deco Apartment in Brunswick East</td>\n",
       "      <td>A large air conditioned room with firm queen s...</td>\n",
       "      <td>This hip area is a crossroads between two grea...</td>\n",
       "      <td>Lindsay</td>\n",
       "      <td>4998</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>As an artist working in animation and video I ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Brunswick East, Victoria, Australia</td>\n",
       "      <td>-37.76606</td>\n",
       "      <td>144.97951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Extra pillows and blankets\", \"Laundromat nea...</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>112.0</td>\n",
       "      <td>169</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>4.69000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.663562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Suite @ Angelus Retreat</td>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;Welcome to ANGELUS Retre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Margaret Jiin</td>\n",
       "      <td>4195</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>I have very special interests in Life and Life...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>-37.90546</td>\n",
       "      <td>145.39447</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"Microwave\", \"Hot tub\", \"Conditioner\", \"Smoke...</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>365.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.598422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Million Dollar Views Over Melbourne</td>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Enjoy Million Dollar ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paul</td>\n",
       "      <td>4728</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>Professional couple who enjoy entertaining in ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>-37.82163</td>\n",
       "      <td>144.96672</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Hot tub\", \"Gym\", \"Washer\", \"Dryer\", \"Kitchen...</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-10-16</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.907755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Melbourne - Old Trafford Apartment</td>\n",
       "      <td>After hosting many guests from all over the wo...</td>\n",
       "      <td>Our street is quiet &amp; secluded but within walk...</td>\n",
       "      <td>Daryl &amp; Dee</td>\n",
       "      <td>4699</td>\n",
       "      <td>Berwick, Australia</td>\n",
       "      <td>We are an active couple who work from home and...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berwick, Victoria, Australia</td>\n",
       "      <td>-38.05725</td>\n",
       "      <td>145.33936</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[\"Laundromat nearby\", \"Private patio or balcon...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>312.0</td>\n",
       "      <td>214</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.93000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.870000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.753590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Comfy Bedroom with Private Bathroom</td>\n",
       "      <td>The apartment is located 180 meters away from ...</td>\n",
       "      <td>Hawthorn is a very family oriented suburb and ...</td>\n",
       "      <td>Kimberley</td>\n",
       "      <td>3215</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>I'm a fun and avid traveller. I've been expose...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.886732</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hawthorn, Victoria, Australia</td>\n",
       "      <td>-37.82025</td>\n",
       "      <td>145.03088</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Essentials\", \"Smoke alarm\", \"Hair dryer\", \"W...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-18</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Light-Filled &amp; Cosy in the Heart of South Yarra</td>\n",
       "      <td>Footsteps from South Yarra Train station, this...</td>\n",
       "      <td>Just 3km from the heart of Melbourne, South Ya...</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>1199</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.886732</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>36.0</td>\n",
       "      <td>South Yarra, Victoria, Australia</td>\n",
       "      <td>-37.83624</td>\n",
       "      <td>144.99299</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Mini fridge\", \"Microwave\", \"Cleaning product...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>268.0</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>4.740000</td>\n",
       "      <td>4.64000</td>\n",
       "      <td>4.740000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>New 6 bedrooms house in Williams Landing</td>\n",
       "      <td>Have fun with the whole family at this stylish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anna</td>\n",
       "      <td>3121</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>I am a travel consultant, love to meet differe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>-37.86326</td>\n",
       "      <td>144.75456</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[\"Microwave\", \"Essentials\", \"Smoke alarm\", \"Ov...</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>69</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>2023-03-04</td>\n",
       "      <td>4.687442</td>\n",
       "      <td>4.761851</td>\n",
       "      <td>4.677927</td>\n",
       "      <td>4.804996</td>\n",
       "      <td>4.82302</td>\n",
       "      <td>4.834347</td>\n",
       "      <td>4.666018</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.544088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Comfortable bedroom in CBD</td>\n",
       "      <td>In Melbourne CBD, within the free tram zone. v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frank</td>\n",
       "      <td>1761</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.886732</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>-37.80913</td>\n",
       "      <td>144.96058</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[\"Essentials\", \"Smoke alarm\", \"Pool\", \"Hair dr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>3.33000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Where the heart is, where the home is</td>\n",
       "      <td>Our apartment is located in an Excellent place...</td>\n",
       "      <td>1 minutes to Ezymart mini market !&lt;br /&gt;&lt;br /...</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>2731</td>\n",
       "      <td>Victoria, Australia</td>\n",
       "      <td>I love sharing with people from all over the w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Central Business District</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Docklands, Victoria, Australia</td>\n",
       "      <td>-37.81353</td>\n",
       "      <td>144.94872</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[\"Extra pillows and blankets\", \"Microwave\", \"B...</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>4.740000</td>\n",
       "      <td>4.87000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "ID                                                      \n",
       "0                               The Stables, Richmond   \n",
       "1       Room in Cool Deco Apartment in Brunswick East   \n",
       "2                         The Suite @ Angelus Retreat   \n",
       "3                 Million Dollar Views Over Melbourne   \n",
       "4                  Melbourne - Old Trafford Apartment   \n",
       "...                                               ...   \n",
       "9995              Comfy Bedroom with Private Bathroom   \n",
       "9996  Light-Filled & Cosy in the Heart of South Yarra   \n",
       "9997         New 6 bedrooms house in Williams Landing   \n",
       "9998                       Comfortable bedroom in CBD   \n",
       "9999            Where the heart is, where the home is   \n",
       "\n",
       "                                            description  \\\n",
       "ID                                                        \n",
       "0     Superbly located hotel style accommodation in ...   \n",
       "1     A large air conditioned room with firm queen s...   \n",
       "2     <b>The space</b><br />Welcome to ANGELUS Retre...   \n",
       "3     <b>The space</b><br /><b>Enjoy Million Dollar ...   \n",
       "4     After hosting many guests from all over the wo...   \n",
       "...                                                 ...   \n",
       "9995  The apartment is located 180 meters away from ...   \n",
       "9996  Footsteps from South Yarra Train station, this...   \n",
       "9997  Have fun with the whole family at this stylish...   \n",
       "9998  In Melbourne CBD, within the free tram zone. v...   \n",
       "9999  Our apartment is located in an Excellent place...   \n",
       "\n",
       "                                  neighborhood_overview      host_name  \\\n",
       "ID                                                                       \n",
       "0     Richmond is a great neighbourhood.  A beautifu...           Ione   \n",
       "1     This hip area is a crossroads between two grea...        Lindsay   \n",
       "2                                                   NaN  Margaret Jiin   \n",
       "3                                                   NaN           Paul   \n",
       "4     Our street is quiet & secluded but within walk...    Daryl & Dee   \n",
       "...                                                 ...            ...   \n",
       "9995  Hawthorn is a very family oriented suburb and ...      Kimberley   \n",
       "9996  Just 3km from the heart of Melbourne, South Ya...           Ruth   \n",
       "9997                                                NaN           Anna   \n",
       "9998                                                NaN          Frank   \n",
       "9999  1 minutes to Ezymart mini market !<br /><br /...        Jasmine   \n",
       "\n",
       "      host_since         host_location  \\\n",
       "ID                                       \n",
       "0           3721  Melbourne, Australia   \n",
       "1           4998  Melbourne, Australia   \n",
       "2           4195  Melbourne, Australia   \n",
       "3           4728  Melbourne, Australia   \n",
       "4           4699    Berwick, Australia   \n",
       "...          ...                   ...   \n",
       "9995        3215  Melbourne, Australia   \n",
       "9996        1199  Melbourne, Australia   \n",
       "9997        3121  Melbourne, Australia   \n",
       "9998        1761  Melbourne, Australia   \n",
       "9999        2731   Victoria, Australia   \n",
       "\n",
       "                                             host_about  host_response_time  \\\n",
       "ID                                                                            \n",
       "0     I'm a working mum who loves being able to shar...                   1   \n",
       "1     As an artist working in animation and video I ...                   2   \n",
       "2     I have very special interests in Life and Life...                   2   \n",
       "3     Professional couple who enjoy entertaining in ...                   3   \n",
       "4     We are an active couple who work from home and...                   2   \n",
       "...                                                 ...                 ...   \n",
       "9995  I'm a fun and avid traveller. I've been expose...                   1   \n",
       "9996                                                NaN                   1   \n",
       "9997  I am a travel consultant, love to meet differe...                   1   \n",
       "9998                                                NaN                   1   \n",
       "9999  I love sharing with people from all over the w...                   1   \n",
       "\n",
       "      host_response_rate  host_acceptance_rate         host_neighbourhood  \\\n",
       "ID                                                                          \n",
       "0               1.000000              0.980000                   Richmond   \n",
       "1               1.000000              0.980000                  Brunswick   \n",
       "2               1.000000              0.780000  Central Business District   \n",
       "3               0.750000              0.920000                  Southbank   \n",
       "4               1.000000              0.870000  Central Business District   \n",
       "...                  ...                   ...                        ...   \n",
       "9995            0.959781              0.886732  Central Business District   \n",
       "9996            0.959781              0.886732  Central Business District   \n",
       "9997            1.000000              0.920000  Central Business District   \n",
       "9998            0.959781              0.886732  Central Business District   \n",
       "9999            0.959781              0.000000  Central Business District   \n",
       "\n",
       "      host_listings_count                        neighbourhood  latitude  \\\n",
       "ID                                                                         \n",
       "0                     2.0        Richmond, Victoria, Australia -37.82030   \n",
       "1                     1.0  Brunswick East, Victoria, Australia -37.76606   \n",
       "2                     2.0       Melbourne, Victoria, Australia -37.90546   \n",
       "3                     4.0       Melbourne, Victoria, Australia -37.82163   \n",
       "4                     1.0         Berwick, Victoria, Australia -38.05725   \n",
       "...                   ...                                  ...       ...   \n",
       "9995                  1.0        Hawthorn, Victoria, Australia -37.82025   \n",
       "9996                 36.0     South Yarra, Victoria, Australia -37.83624   \n",
       "9997                 36.0       Melbourne, Victoria, Australia -37.86326   \n",
       "9998                  2.0       Melbourne, Victoria, Australia -37.80913   \n",
       "9999                  1.0       Docklands, Victoria, Australia -37.81353   \n",
       "\n",
       "      longitude  room_type  accommodates  bathrooms  bedrooms  beds  \\\n",
       "ID                                                                    \n",
       "0     144.99016          0             2        1.0       1.0   1.0   \n",
       "1     144.97951          2             2        1.0       1.0   1.0   \n",
       "2     145.39447          0             4        2.5       2.0   4.0   \n",
       "3     144.96672          2             2        2.5       1.0   1.0   \n",
       "4     145.33936          0             5        1.0       3.0   3.0   \n",
       "...         ...        ...           ...        ...       ...   ...   \n",
       "9995  145.03088          2             2        1.0       1.0   1.0   \n",
       "9996  144.99299          0             2        1.0       1.0   1.0   \n",
       "9997  144.75456          0            16        3.5       6.0   8.0   \n",
       "9998  144.96058          2             2        0.5       1.0   2.0   \n",
       "9999  144.94872          0             5        1.0       2.0   3.0   \n",
       "\n",
       "                                              amenities  minimum_nights  \\\n",
       "ID                                                                        \n",
       "0     [\"Sukin conditioner\", \"Extra pillows and blank...               2   \n",
       "1     [\"Extra pillows and blankets\", \"Laundromat nea...               4   \n",
       "2     [\"Microwave\", \"Hot tub\", \"Conditioner\", \"Smoke...               2   \n",
       "3     [\"Hot tub\", \"Gym\", \"Washer\", \"Dryer\", \"Kitchen...               1   \n",
       "4     [\"Laundromat nearby\", \"Private patio or balcon...               1   \n",
       "...                                                 ...             ...   \n",
       "9995  [\"Essentials\", \"Smoke alarm\", \"Hair dryer\", \"W...               1   \n",
       "9996  [\"Mini fridge\", \"Microwave\", \"Cleaning product...               1   \n",
       "9997  [\"Microwave\", \"Essentials\", \"Smoke alarm\", \"Ov...               2   \n",
       "9998  [\"Essentials\", \"Smoke alarm\", \"Pool\", \"Hair dr...               1   \n",
       "9999  [\"Extra pillows and blankets\", \"Microwave\", \"B...               2   \n",
       "\n",
       "      maximum_nights  minimum_minimum_nights  maximum_minimum_nights  \\\n",
       "ID                                                                     \n",
       "0                 14                     2.0                       2   \n",
       "1                 27                     4.0                       4   \n",
       "2                365                     2.0                       2   \n",
       "3                730                     1.0                       1   \n",
       "4                 14                     1.0                       1   \n",
       "...              ...                     ...                     ...   \n",
       "9995            1125                     1.0                       1   \n",
       "9996              90                     3.0                       7   \n",
       "9997             365                     2.0                       2   \n",
       "9998            1125                     1.0                       1   \n",
       "9999            1125                     2.0                       2   \n",
       "\n",
       "      minimum_maximum_nights  maximum_maximum_nights  minimum_nights_avg_ntm  \\\n",
       "ID                                                                             \n",
       "0                       1125                  1125.0                     2.0   \n",
       "1                         27                    27.0                     4.0   \n",
       "2                        365                   365.0                     2.0   \n",
       "3                        730                   730.0                     1.0   \n",
       "4                         14                    14.0                     1.0   \n",
       "...                      ...                     ...                     ...   \n",
       "9995                    1125                  1125.0                     1.0   \n",
       "9996                      90                    90.0                     4.0   \n",
       "9997                     365                   365.0                     2.0   \n",
       "9998                    1125                  1125.0                     1.0   \n",
       "9999                    1125                  1125.0                     2.0   \n",
       "\n",
       "      maximum_nights_avg_ntm  availability_30  availability_60  \\\n",
       "ID                                                               \n",
       "0                     1125.0                0                0   \n",
       "1                       27.0                0               12   \n",
       "2                      365.0               30               60   \n",
       "3                      730.0               30               60   \n",
       "4                       14.0               17               21   \n",
       "...                      ...              ...              ...   \n",
       "9995                  1125.0                0                0   \n",
       "9996                    90.0                1                1   \n",
       "9997                   365.0                9               39   \n",
       "9998                  1125.0                0                0   \n",
       "9999                  1125.0                0                0   \n",
       "\n",
       "      availability_90  availability_365  number_of_reviews  \\\n",
       "ID                                                           \n",
       "0                   0              12.0                741   \n",
       "1                  22             112.0                169   \n",
       "2                  90             365.0                  8   \n",
       "3                  90             365.0                  2   \n",
       "4                  51             312.0                214   \n",
       "...               ...               ...                ...   \n",
       "9995                0               0.0                  2   \n",
       "9996                1             268.0                 42   \n",
       "9997               69             340.0                  0   \n",
       "9998                0               0.0                  3   \n",
       "9999                0               0.0                 46   \n",
       "\n",
       "      number_of_reviews_ltm  number_of_reviews_l30d first_review last_review  \\\n",
       "ID                                                                             \n",
       "0                        37                       1   2013-03-29  2023-02-18   \n",
       "1                        25                       3   2013-01-12  2023-03-08   \n",
       "2                         2                       0   2015-07-06  2022-06-13   \n",
       "3                         0                       0   2011-10-16  2012-01-27   \n",
       "4                        39                       4   2010-11-24  2023-03-03   \n",
       "...                     ...                     ...          ...         ...   \n",
       "9995                      0                       0   2016-07-18  2016-07-25   \n",
       "9996                      9                       0   2019-03-06  2023-01-15   \n",
       "9997                      0                       0   2022-04-11  2023-03-04   \n",
       "9998                      0                       0   2020-01-26  2020-02-25   \n",
       "9999                      0                       0   2020-11-10  2021-12-30   \n",
       "\n",
       "      review_scores_rating  review_scores_accuracy  review_scores_cleanliness  \\\n",
       "ID                                                                              \n",
       "0                 4.880000                4.910000                   4.970000   \n",
       "1                 4.480000                4.640000                   3.970000   \n",
       "2                 4.750000                4.880000                   4.750000   \n",
       "3                 4.500000                4.000000                   4.500000   \n",
       "4                 4.860000                4.910000                   4.980000   \n",
       "...                    ...                     ...                        ...   \n",
       "9995              4.500000                4.000000                   5.000000   \n",
       "9996              4.210000                4.500000                   4.290000   \n",
       "9997              4.687442                4.761851                   4.677927   \n",
       "9998              3.000000                4.000000                   3.000000   \n",
       "9999              4.910000                4.830000                   4.930000   \n",
       "\n",
       "      review_scores_checkin  review_scores_communication  \\\n",
       "ID                                                         \n",
       "0                  4.940000                      4.93000   \n",
       "1                  4.720000                      4.69000   \n",
       "2                  4.880000                      4.50000   \n",
       "3                  4.000000                      4.00000   \n",
       "4                  4.910000                      4.93000   \n",
       "...                     ...                          ...   \n",
       "9995               5.000000                      5.00000   \n",
       "9996               4.740000                      4.64000   \n",
       "9997               4.804996                      4.82302   \n",
       "9998               2.330000                      3.33000   \n",
       "9999               4.740000                      4.87000   \n",
       "\n",
       "      review_scores_location  review_scores_value  \\\n",
       "ID                                                  \n",
       "0                   4.930000             4.820000   \n",
       "1                   4.650000             4.600000   \n",
       "2                   5.000000             4.750000   \n",
       "3                   5.000000             4.000000   \n",
       "4                   4.900000             4.870000   \n",
       "...                      ...                  ...   \n",
       "9995                4.500000             4.500000   \n",
       "9996                4.740000             4.190000   \n",
       "9997                4.834347             4.666018   \n",
       "9998                4.000000             3.330000   \n",
       "9999                4.960000             4.910000   \n",
       "\n",
       "      calculated_host_listings_count  \\\n",
       "ID                                     \n",
       "0                                  2   \n",
       "1                                  1   \n",
       "2                                  2   \n",
       "3                                  1   \n",
       "4                                  1   \n",
       "...                              ...   \n",
       "9995                               1   \n",
       "9996                              36   \n",
       "9997                              36   \n",
       "9998                               2   \n",
       "9999                               1   \n",
       "\n",
       "      calculated_host_listings_count_entire_homes  \\\n",
       "ID                                                  \n",
       "0                                               2   \n",
       "1                                               0   \n",
       "2                                               2   \n",
       "3                                               0   \n",
       "4                                               1   \n",
       "...                                           ...   \n",
       "9995                                            0   \n",
       "9996                                           36   \n",
       "9997                                           36   \n",
       "9998                                            0   \n",
       "9999                                            1   \n",
       "\n",
       "      calculated_host_listings_count_private_rooms  \\\n",
       "ID                                                   \n",
       "0                                                0   \n",
       "1                                                1   \n",
       "2                                                0   \n",
       "3                                                1   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "9995                                             1   \n",
       "9996                                             0   \n",
       "9997                                             0   \n",
       "9998                                             2   \n",
       "9999                                             0   \n",
       "\n",
       "      calculated_host_listings_count_shared_rooms  reviews_per_month   price  \\\n",
       "ID                                                                             \n",
       "0                                               0           6.110000   132.0   \n",
       "1                                               0           1.370000    39.0   \n",
       "2                                               0           0.090000   270.0   \n",
       "3                                               0           0.010000  1000.0   \n",
       "4                                               0           1.430000   116.0   \n",
       "...                                           ...                ...     ...   \n",
       "9995                                            0           0.020000     NaN   \n",
       "9996                                            0           0.860000     NaN   \n",
       "9997                                            0           1.544088     NaN   \n",
       "9998                                            0           0.080000     NaN   \n",
       "9999                                            0           1.610000     NaN   \n",
       "\n",
       "      email  phone  work_email  amenity_count  smoke_alarm  kitchen  \\\n",
       "ID                                                                    \n",
       "0       1.0    1.0         0.0             38            1        0   \n",
       "1       1.0    1.0         0.0             57            1        1   \n",
       "2       1.0    1.0         0.0             21            1        1   \n",
       "3       1.0    1.0         0.0             13            0        1   \n",
       "4       1.0    1.0         1.0             49            1        1   \n",
       "...     ...    ...         ...            ...          ...      ...   \n",
       "9995    1.0    1.0         0.0             13            1        1   \n",
       "9996    1.0    1.0         1.0             40            1        1   \n",
       "9997    1.0    1.0         0.0             42            1        1   \n",
       "9998    0.0    1.0         0.0             10            1        1   \n",
       "9999    1.0    1.0         0.0             42            1        1   \n",
       "\n",
       "      essentials  hangers  wifi  source_previous scrape  host_is_superhost_t  \\\n",
       "ID                                                                             \n",
       "0              1        1     1                       0                    0   \n",
       "1              1        1     0                       0                    0   \n",
       "2              0        0     1                       0                    1   \n",
       "3              0        0     1                       0                    0   \n",
       "4              1        1     1                       0                    1   \n",
       "...          ...      ...   ...                     ...                  ...   \n",
       "9995           1        1     1                       1                    0   \n",
       "9996           1        1     1                       0                    0   \n",
       "9997           1        1     1                       0                    0   \n",
       "9998           1        1     1                       1                    0   \n",
       "9999           1        1     1                       0                    0   \n",
       "\n",
       "      host_has_profile_pic_t  host_identity_verified_t  has_availability_t  \\\n",
       "ID                                                                           \n",
       "0                          1                         1                   1   \n",
       "1                          1                         1                   1   \n",
       "2                          1                         1                   1   \n",
       "3                          1                         1                   1   \n",
       "4                          1                         1                   1   \n",
       "...                      ...                       ...                 ...   \n",
       "9995                       1                         1                   1   \n",
       "9996                       1                         0                   1   \n",
       "9997                       1                         1                   1   \n",
       "9998                       1                         1                   1   \n",
       "9999                       1                         1                   1   \n",
       "\n",
       "      instant_bookable_t  property_type_Entire home  \\\n",
       "ID                                                    \n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "9995                   0                          0   \n",
       "9996                   1                          0   \n",
       "9997                   1                          1   \n",
       "9998                   1                          0   \n",
       "9999                   0                          0   \n",
       "\n",
       "      property_type_Entire rental unit  property_type_Private room in home  \\\n",
       "ID                                                                           \n",
       "0                                    0                                   0   \n",
       "1                                    0                                   0   \n",
       "2                                    1                                   0   \n",
       "3                                    0                                   0   \n",
       "4                                    1                                   0   \n",
       "...                                ...                                 ...   \n",
       "9995                                 0                                   0   \n",
       "9996                                 1                                   0   \n",
       "9997                                 0                                   0   \n",
       "9998                                 0                                   0   \n",
       "9999                                 1                                   0   \n",
       "\n",
       "      property_type_Private room in rental unit  property_type_other  \\\n",
       "ID                                                                     \n",
       "0                                             0                    1   \n",
       "1                                             1                    0   \n",
       "2                                             0                    0   \n",
       "3                                             1                    0   \n",
       "4                                             0                    0   \n",
       "...                                         ...                  ...   \n",
       "9995                                          1                    0   \n",
       "9996                                          0                    0   \n",
       "9997                                          0                    0   \n",
       "9998                                          1                    0   \n",
       "9999                                          0                    0   \n",
       "\n",
       "      neighbourhood_cleansed  log_price  \n",
       "ID                                       \n",
       "0                          3   4.882802  \n",
       "1                          5   3.663562  \n",
       "2                          4   5.598422  \n",
       "3                          0   6.907755  \n",
       "4                          0   4.753590  \n",
       "...                      ...        ...  \n",
       "9995                       5        NaN  \n",
       "9996                       2        NaN  \n",
       "9997                       5        NaN  \n",
       "9998                       0        NaN  \n",
       "9999                       0        NaN  \n",
       "\n",
       "[10000 rows x 73 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cec86c-f5d6-4588-b4c4-8b3db88dd311",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font color='darkblue'>\n",
    "* Created <b>log_price</b> variable which is the logarithmic transformation of the price variable, to scale the price and reduce the effect of the outliers and make the distribution more normal.\n",
    "</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b7db1-9008-4c8a-8e49-82cce1f64bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df7 = df6\n",
    "df7.drop(['amenities'], axis=1, inplace=True) \n",
    "#df7.drop(['name', 'description','neighborhood_overview','host_name',\n",
    "#          'host_about','neighbourhood','latitude','longitude'], axis=1, inplace=True)\n",
    "df7.drop(['name', 'description','neighborhood_overview','host_name',\n",
    "          'host_about','neighbourhood'], axis=1, inplace=True)\n",
    "\n",
    "df7.drop(['host_location', #'host_response_rate','host_acceptance_rate',\n",
    "          'host_neighbourhood',\n",
    "          #'host_listings_count'\n",
    "         ], \n",
    "          axis=1, inplace=True)\n",
    "df7.drop(['minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'], axis=1, inplace=True)\n",
    "#df7.drop(['number_of_reviews','number_of_reviews_ltm', 'number_of_reviews_l30d'], axis=1, inplace=True)\n",
    "df7.drop(['first_review', 'last_review'], axis=1, inplace=True)\n",
    "#df7.drop(['review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value'], axis=1, inplace=True) \n",
    "df7.drop(['calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms'], axis=1, inplace=True)\n",
    "df7.drop(['reviews_per_month'], axis=1, inplace=True)\n",
    " \n",
    "df7\n",
    "\n",
    "df7.to_csv(\"df_7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee23b8-8489-4786-b832-e40c4f498242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f258c6-5c72-4c12-a210-aa33c82533f2",
   "metadata": {},
   "source": [
    "\n",
    "#### <font color='darkblue'> Feature - selection\n",
    "<font color='darkblue'>\n",
    "* Dropped features for initial analysis.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16475c",
   "metadata": {},
   "source": [
    "**Task 2, Question 6**: Perform exploratory data analysis to measure the relationship between the features and the target and write up your findings. \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist(df7['log_price'], bins=100)\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a965eb-e661-4772-af72-98f19e1bae41",
   "metadata": {},
   "source": [
    "`(Task 2, Question 6 Text Here)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f6968-d9c2-422f-9935-eba856b3c028",
   "metadata": {},
   "source": [
    "--- \n",
    "## Task 3: Fit and tune a forecasting model/Submit predictions/Report score and ranking {-}\n",
    "\n",
    "Make sure you **clearly explain each step** you do, both in text and on the recoded video.\n",
    "\n",
    "1. Build a machine learning (ML) regression model by taking into account the outcomes of Tasks 1 & 2 (Explain carefully)\n",
    "2. Fit the model and tune hyperparameters via cross-validation: make sure you comment and explain each step clearly\n",
    "3. Create predictions using the test dataset and submit your predictions on Kaggle's competition page\n",
    "4. Provide Kaggle ranking and **score** (screenshot your best submission) and Comment\n",
    "5. Make sure your Python code works, so that a marker that can replicate your all of your results and obtain the same RMSE from Kaggle\n",
    "\n",
    "- Hint: to perform well in this assignment you will need to iterate Tasks 2 & 3, creating new features and training various models in order to find the best one.\n",
    "\n",
    "Total Marks: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86518aa-9f3d-4c5d-91ca-c88cc10ccc42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9 = df7\n",
    "df9.to_csv(\"df_9.csv\")\n",
    "\n",
    "df_test_train = pd.read_csv(\"df_7.csv\")\n",
    "\n",
    "df_train = df_test_train.iloc[:7000]\n",
    "df_train = df_train[df_train['price'] < 4000]\n",
    "\n",
    "df_test = df_test_train.iloc[7000:]\n",
    "\n",
    "y_train = df_train['log_price'].values.ravel()\n",
    "\n",
    "#y_test = df_test['log_price']\n",
    "\n",
    "X_train = df_train.drop(['ID', 'price','log_price','latitude','longitude','source_previous scrape'], axis=1).values\n",
    "\n",
    "X_test = df_test.drop(['ID', 'price','log_price','latitude','longitude','source_previous scrape'], axis=1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd5df70d-063a-4b09-b655-6bfb8e22352a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766210f-138f-4099-a6b8-5884432c67e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit and predit on test data\n",
    "\n",
    "#X_train, y_train = make_regression(n_samples=150, n_features=33, random_state=42)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), \n",
    "       RandomForestRegressor(random_state=42, n_estimators=400, max_depth=20))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.exp(y_pred)\n",
    "\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred_dollar})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "pred.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828695d-b100-4ea9-bbc0-5b53257e1186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fd7ed-e6ec-4c3f-b8f7-e4637743c58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test on subset of training data\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     RandomForestRegressor(random_state=42, n_estimators=400, max_depth=20))\n",
    "\n",
    "\n",
    "df_test_t = pd.read_csv(\"df_test.csv\")\n",
    "\n",
    "y_test = df_test_t['log_price'].values\n",
    "\n",
    "X_test = df_test_t.drop(['ID', 'price','log_price'], axis=1).values\n",
    "\n",
    "x = pipe.fit(X_train, y_train)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "y_test_dollar = np.round(np.exp(y_test))\n",
    "rmse = np.sqrt(mean_squared_error(y_test_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "test_pred = pd.DataFrame({\"price\":y_test_dollar, \"pred\":y_pred_dollar})\n",
    "test_pred.head(100)\n",
    "#print(train_pred.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd48bad-cae9-4e89-8d04-8aff131a48ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "n_folds = 20\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = -cross_val_score(pipe_rf, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "mse = np.mean(cv_scores)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipe_rf.predict(X_train)\n",
    "mse = mean_squared_error(y_train,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# calculate RMSE in original scale\n",
    "y_pred_dollar = np.exp(y_pred)\n",
    "y_test_dollar = np.exp(y_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error in AUD: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a68df-317b-4936-9f80-054fadaeb18d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X_test1 = df7.drop(['price','source_previous scrape','host_since','host_has_profile_pic_t','host_identity_verified_t'\n",
    "#             ], axis=1).iloc[7000:10000].values\n",
    "y_pred1 = pipe_rf.predict(X_test)\n",
    "y_pred1\n",
    "#len(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d489b8-bccb-4195-a06d-c153020fc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE in original scale\n",
    "y_pred_dollar = np.exp(y_pred)\n",
    "y_test_dollar = np.exp(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error in AUD: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da87c1-b36e-4265-a150-a222f6073ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29d4aa5f-3653-4671-9a39-38a255b1c584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#df6  = pd.read_csv('df_6.csv')\n",
    "\n",
    "df_train = df6[:7000]\n",
    "#df_train = df_train[df_train['price'] < 4001]\n",
    "\n",
    "df_test = df6[7000:]\n",
    "\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "'property_type','amenities']\n",
    "\n",
    "\n",
    "dfxx = df6.drop(columns=columns_to_drop).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efae38-e2dc-441e-b909-2e0b5c0831d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "\n",
    "#df6  = pd.read_csv('df_6.csv')\n",
    "\n",
    "df_train = df6[:7000]\n",
    "#df_train = df_train[df_train['price'] < 4001]\n",
    "\n",
    "df_test = df6[7000:]\n",
    "\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "'amenities',\n",
    "    \n",
    "    \n",
    "   \n",
    "'price'\n",
    ",'log_price'\n",
    "    \n",
    "#,'calculated_host_listings_count_shared_rooms'\n",
    "#,'calculated_host_listings_count_entire_homes'\n",
    "#,'email'\n",
    "#,'smoke_alarm'\n",
    "#,'property_type_Entire home'\n",
    "#,'maximum_nights_avg_ntm'\n",
    "#,'minimum_nights'\n",
    "#,'calculated_host_listings_count'\n",
    "#,'maximum_maximum_nights'\n",
    "#,'minimum_minimum_nights'\n",
    "#,'availability_60'\n",
    "#,'review_scores_rating'\n",
    "\n",
    ",'review_scores_location'\n",
    ",'number_of_reviews_l30d'\n",
    ",'maximum_minimum_nights'\n",
    ",'reviews_per_month'\n",
    ",'minimum_maximum_nights'\n",
    ",'availability_365'\n",
    ",'review_scores_cleanliness'\n",
    ",'review_scores_value'\n",
    ",'number_of_reviews'\n",
    ",'availability_90'\n",
    ",'number_of_reviews_ltm'\n",
    ",'host_listings_count'\n",
    ",'review_scores_communication'\n",
    ",'minimum_nights_avg_ntm'\n",
    ",'longitude'\n",
    ",'maximum_nights'\n",
    ",'host_response_rate'\n",
    ",'amenity_count'\n",
    ",'host_identity_verified_t'\n",
    ",'review_scores_accuracy'\n",
    ",'host_acceptance_rate'\n",
    ",'source_previous scrape'\n",
    ",'hangers'\n",
    ",'review_scores_checkin'\n",
    ",'latitude'\n",
    ",'wifi'\n",
    ",'kitchen'\n",
    ",'host_since'\n",
    ",'beds'\n",
    ",'property_type_other'\n",
    ",'property_type_Entire rental unit'\n",
    ",'property_type_Private room in rental unit'\n",
    ",'host_response_time'\n",
    ",'host_is_superhost_t'\n",
    ",'work_email'\n",
    ",'essentials'\n",
    ",'phone'\n",
    ",'has_availability_t'\n",
    ",'host_has_profile_pic_t'\n",
    "\n",
    "    \n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "y_train = df_train['log_price'].values\n",
    "\n",
    "X_train = df_train.drop(columns=columns_to_drop).values\n",
    "\n",
    "X_test =  df_test.drop(columns=columns_to_drop).values\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300,400,500,600,700,800],  # Number of boosting stages to perform\n",
    "#    'learning_rate': [0.1, 0.05, 0.01],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [3, 4, 5, 10, 15, 20, 25, 30,50 ]  # Maximum depth of each decision tree\n",
    "}\n",
    "\n",
    "gb_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs = 24)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "#print(best_params)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     RandomForestRegressor(random_state=42, **best_params))\n",
    "    \n",
    "#pipe = make_pipeline(StandardScaler(),\n",
    "#                     RandomForestRegressor(random_state=42, n_estimators=20 , max_depth=700))\n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "x = pipe.fit(X_train, y_train)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_train)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "y_train_dollar = np.round(np.exp(y_train))\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "train_pred = pd.DataFrame({\"price\":y_train_dollar, \"pred\":y_pred_dollar})\n",
    "train_pred.head(5)\n",
    "\n",
    "\n",
    "#df_test = pd.read_csv(\"test.csv\")\n",
    "#X_test = df_test.drop(['ID'], axis=1).values\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "#test_pred = pd.DataFrame({\"price\":y_test_dollar, \"pred\":y_test_pred_dollar})\n",
    "#test_pred.head(100)\n",
    "\n",
    "\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\": np.exp(y_pred)})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "pred.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be016f-8bec-4b84-8cbe-53787d3d9448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b6276-5451-47ac-b67d-a8dade8375fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c50ef3-01a1-46df-a6cc-4ed7936d5a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LASSO\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#df6  = pd.read_csv('df_6.csv')\n",
    "\n",
    "df_train = df6[:7000]\n",
    "\n",
    "df_test = df6[7000:]\n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "    \n",
    "   \n",
    "'price'\n",
    ",'log_price'\n",
    "\n",
    "    \n",
    ",'minimum_nights_avg_ntm'\n",
    ",'availability_365'\n",
    ",'maximum_maximum_nights'\n",
    ",'host_response_rate'\n",
    ",'longitude'\n",
    ",'availability_90'\n",
    ",'host_listings_count'\n",
    ",'minimum_nights'\n",
    ",'availability_60'\n",
    ",'number_of_reviews_ltm'\n",
    ",'amenity_count'\n",
    ",'number_of_reviews'\n",
    ",'reviews_per_month'\n",
    ",'beds'\n",
    ",'maximum_nights'\n",
    ",'review_scores_cleanliness'\n",
    ",'host_acceptance_rate'\n",
    ",'hangers'\n",
    ",'wifi'\n",
    ",'latitude'\n",
    ",'work_email'\n",
    ",'source_previous scrape'\n",
    ",'kitchen'\n",
    ",'maximum_nights_avg_ntm'\n",
    ",'review_scores_accuracy'\n",
    ",'review_scores_checkin'\n",
    ",'host_is_superhost_t'\n",
    ",'review_scores_communication'\n",
    ",'essentials'\n",
    ",'host_since'\n",
    ",'host_response_time'\n",
    ",'host_has_profile_pic_t'\n",
    ",'phone'\n",
    "#,'has_availability_t'\n",
    "   \n",
    "    \n",
    "]\n",
    "\n",
    "y_train = df_train['log_price'].values\n",
    "\n",
    "X_train = df_train.drop(columns=columns_to_drop).values\n",
    "\n",
    "X_test =  df_test.drop(columns=columns_to_drop).values\n",
    "  \n",
    "\n",
    "    \n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'max_iter': [1000, 2000, 3000,4000],\n",
    "    'tol': [0.01,0.001, 0.0001, 0.00001]\n",
    "}\n",
    "\n",
    "\n",
    "gb_model = Lasso(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, n_jobs=24)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     Lasso(random_state=42, **best_params))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_train)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "y_train_dollar = np.round(np.exp(y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "train_pred = pd.DataFrame({\"price\":y_train_dollar, \"pred\":y_pred_dollar})\n",
    "train_pred.head(5)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred_dollar})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28179b9c-9d73-429a-a773-ccc38f681e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#df6  = pd.read_csv('df_6.csv')\n",
    "\n",
    "df_train = df6[:7000]\n",
    "#df_train = df_train[df_train['price'] < 4000]\n",
    "\n",
    "df_test = df6[7000:]\n",
    "\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "    \n",
    "   \n",
    "'price'\n",
    ",'log_price'\n",
    "\n",
    "    \n",
    ",'minimum_nights_avg_ntm'\n",
    ",'availability_365'\n",
    ",'maximum_maximum_nights'\n",
    ",'host_response_rate'\n",
    ",'longitude'\n",
    ",'availability_90'\n",
    ",'host_listings_count'\n",
    ",'minimum_nights'\n",
    ",'availability_60'\n",
    ",'number_of_reviews_ltm'\n",
    ",'amenity_count'\n",
    ",'number_of_reviews'\n",
    ",'reviews_per_month'\n",
    ",'beds'\n",
    ",'maximum_nights'\n",
    ",'review_scores_cleanliness'\n",
    ",'host_acceptance_rate'\n",
    ",'hangers'\n",
    ",'wifi'\n",
    ",'latitude'\n",
    ",'work_email'\n",
    ",'source_previous scrape'\n",
    ",'kitchen'\n",
    ",'maximum_nights_avg_ntm'\n",
    ",'review_scores_accuracy'\n",
    ",'review_scores_checkin'\n",
    ",'host_is_superhost_t'\n",
    "#,'review_scores_communication'\n",
    "#,'essentials'\n",
    "#,'host_since'\n",
    "#,'host_response_time'\n",
    "#,'host_has_profile_pic_t'\n",
    "#,'phone'\n",
    "#,'has_availability_t'\n",
    "\n",
    "   \n",
    "]\n",
    "\n",
    "y_train = df_train['log_price'].values\n",
    "\n",
    "X_train = df_train.drop(columns=columns_to_drop).values\n",
    "\n",
    "X_test =  df_test.drop(columns=columns_to_drop).values\n",
    "  \n",
    "\n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "    \n",
    " \n",
    "   \n",
    "    \n",
    "]\n",
    "    \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300,400,500],  # Number of boosting stages to perform\n",
    "    'learning_rate': [0.1, 0.05, 0.01,0.5],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [3, 4, 5]  # Maximum depth of each decision tree\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, n_jobs=24)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     GradientBoostingRegressor(random_state=42, **best_params))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_train)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "y_train_dollar = np.round(np.exp(y_train))\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "train_pred = pd.DataFrame({\"price\":y_train_dollar, \"pred\":y_pred_dollar})\n",
    "train_pred.head(5)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\":np.exp(y_pred)})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "pred.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef21422-d7f4-4d77-8b6a-7fb4009a35d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#df6  = pd.read_csv('df_6.csv')\n",
    "\n",
    "df_train = df6[:7000]\n",
    "\n",
    "df_test = df6[7000:]\n",
    "\n",
    "    \n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "    \n",
    "   \n",
    "'price'\n",
    ",'log_price'\n",
    "\n",
    "    \n",
    ",'minimum_nights_avg_ntm'\n",
    ",'availability_365'\n",
    ",'maximum_maximum_nights'\n",
    ",'host_response_rate'\n",
    ",'longitude'\n",
    ",'availability_90'\n",
    ",'host_listings_count'\n",
    ",'minimum_nights'\n",
    ",'availability_60'\n",
    ",'number_of_reviews_ltm'\n",
    ",'amenity_count'\n",
    ",'number_of_reviews'\n",
    ",'reviews_per_month'\n",
    ",'beds'\n",
    ",'maximum_nights'\n",
    ",'review_scores_cleanliness'\n",
    ",'host_acceptance_rate'\n",
    ",'hangers'\n",
    ",'wifi'\n",
    ",'latitude'\n",
    ",'work_email'\n",
    ",'source_previous scrape'\n",
    ",'kitchen'\n",
    "#,'maximum_nights_avg_ntm'\n",
    "#,'review_scores_accuracy'\n",
    "#,'review_scores_checkin'\n",
    "#,'host_is_superhost_t'\n",
    "#,'review_scores_communication'\n",
    "#,'essentials'\n",
    "#,'host_since'\n",
    "#,'host_response_time'\n",
    "#,'host_has_profile_pic_t'\n",
    "#,'phone'\n",
    "#,'has_availability_t'\n",
    "\n",
    "  \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "y_train = df_train['log_price'].values\n",
    "\n",
    "X_train = df_train.drop(columns=columns_to_drop).values\n",
    "\n",
    "X_test =  df_test.drop(columns=columns_to_drop).values\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'l1_ratio': [0.2, 0.5, 0.8],\n",
    "    'max_iter': [1000, 2000, 3000],\n",
    "    'tol': [0.001, 0.0001, 0.00001]\n",
    "}\n",
    "\n",
    "gb_model = ElasticNet()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, n_jobs=24)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     ElasticNet(**best_params))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_train)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "y_train_dollar = np.round(np.exp(y_train))\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train_dollar, y_pred_dollar))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "train_pred = pd.DataFrame({\"price\":y_train_dollar, \"pred\":y_pred_dollar})\n",
    "train_pred.head(5)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred_dollar})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "pred.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee2f68-577a-440d-8bbf-fc6c34c2cb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import plot_importance, DMatrix\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#df6  = pd.read_csv('df_6.csv')\n",
    "\n",
    "df_train = df6[:7000]\n",
    "\n",
    "#df_X = df_train[df_train['price'] < 4000]\n",
    "\n",
    "columns_to_drop = [\n",
    "'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "'host_neighbourhood','neighbourhood','amenities','first_review','last_review','price',\n",
    "'log_price'\n",
    "]\n",
    "\n",
    "\n",
    "y_train = df_X['log_price'].values\n",
    "\n",
    "X_train = df_X.drop(columns=columns_to_drop).values\n",
    "\n",
    "feature_names = df_train.drop(columns=columns_to_drop).columns\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(45, 8))\n",
    "plot_importance(model, ax=ax)\n",
    "ax.set_yticks(range(len(feature_names)))\n",
    "ax.set_yticklabels(feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b363f4-5270-46a9-8fb8-85214ee191fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importance })\n",
    "\n",
    "df_importances['Rank'] = df_importances['Importance'].rank(ascending=False)\n",
    "\n",
    "# Sort the importances by rank\n",
    "df_importances = df_importances.sort_values(by='Rank')\n",
    "\n",
    "# Print the feature importances with ranks\n",
    "print(len(importance))\n",
    "print(len(feature_names))\n",
    "df_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e9efc-e6ca-4906-878a-0a6ff3621b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb717f3d-5983-498a-8710-d213cba1db5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_test = pd.read_csv(\"test.csv\")\n",
    "#X_test = df_test.drop(['ID'], axis=1).values\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_dollar = np.round(np.exp(y_pred))\n",
    "\n",
    "#test_pred = pd.DataFrame({\"price\":y_test_dollar, \"pred\":y_test_pred_dollar})\n",
    "#test_pred.head(100)\n",
    "\n",
    "\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred_dollar})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "pred.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c07db6-8b4d-4e5c-8994-495e40538641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed0bc7-3acc-443d-be21-7ea3250ea70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "y_test_pred_dollar = np.round(np.exp(y_test_pred))\n",
    "\n",
    "y_test_dollar = np.round(np.exp(y_test))\n",
    "rmse = np.sqrt(mean_squared_error(y_test_dollar, y_test_pred_dollar))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "test_pred = pd.DataFrame({\"price\":y_test_dollar, \"pred\":y_test_pred_dollar})\n",
    "test_pred.head(100)\n",
    "#print(train_pred.head(15))\n",
    "\n",
    "\n",
    "#test_id = np.arange(7000, 10000, 1)\n",
    "#pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred_dollar})\n",
    "#pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de075d-edc3-44a7-9212-388ffa256ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred1 = pipe.predict(X_test)\n",
    "\n",
    "y_pred1_dollar = np.round(np.exp(y_pred1))\n",
    "test_id = np.arange(7000, 10000, 1)\n",
    "pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred1_dollar})\n",
    "pred.to_csv(\"pricepredictions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f59ee3-bc6a-4950-8fc4-97bffa9fe510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xxxx = sum(train_pred['price']) - sum(train_pred['pred']) \n",
    "\n",
    "xxxx\n",
    "\n",
    "#test_id = np.arange(7000, 10000, 1)\n",
    "#pred = pd.DataFrame({\"ID\":test_id, \"price\":y_pred_dollar})\n",
    "#pred.to_csv(\"pricepredictions.csv\", index=False, header=True)\n",
    "\n",
    "#train_pred.to_csv(\"train_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178195d6-cd62-405e-b933-8d30f0ea33cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "\n",
    "\n",
    "param_grid = {'randomforestregressor__n_estimators': [100, 200, 300],\n",
    "              'randomforestregressor__max_depth': [1, 3, 5, 10, 20, None]\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a9e2e-d2cd-42d2-bbd7-1f43ba50d4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(xxx['price'] > 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5707fff-6090-4372-9573-7b9bd0f1fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494b916-4849-44ab-a950-c728e34f335e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b4787-8268-4a43-bcc8-758a1e6eaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = [\n",
    "# 'name','description','neighborhood_overview','host_name','host_location','host_about',\n",
    "# 'host_neighbourhood','neighbourhood','amenities','first_review','last_review',\n",
    "    \n",
    "# 'minimum_minimum_nights',\n",
    "# 'maximum_minimum_nights',\n",
    "# 'minimum_maximum_nights',\n",
    "# 'maximum_maximum_nights',\n",
    "# 'minimum_nights_avg_ntm',\n",
    "# 'maximum_nights_avg_ntm',\n",
    "\n",
    "# 'calculated_host_listings_count',\n",
    "# 'calculated_host_listings_count_entire_homes',\n",
    "# 'calculated_host_listings_count_private_rooms',\n",
    "# 'calculated_host_listings_count_shared_rooms'\n",
    "    \n",
    "# ,'price'\n",
    "# ,'host_since'\n",
    "# ,'host_response_time'\n",
    "# #,'host_response_rate'\n",
    "# #,'host_acceptance_rate'\n",
    "# ,'host_listings_count'\n",
    "# ,'latitude'\n",
    "# ,'longitude'\n",
    "# #,'room_type'\n",
    "# #,'accommodates'\n",
    "# #,'bathrooms'\n",
    "# #,'bedrooms'\n",
    "# #,'beds'\n",
    "# ,'minimum_nights'\n",
    "# ,'maximum_nights'\n",
    "# ,'availability_30'\n",
    "# ,'availability_60'\n",
    "# ,'availability_90'\n",
    "# ,'availability_365'\n",
    "# #,'number_of_reviews'\n",
    "# #,'number_of_reviews_ltm'\n",
    "# ,'number_of_reviews_l30d'\n",
    "# #,'review_scores_rating'\n",
    "# #,'review_scores_accuracy'\n",
    "# #,'review_scores_cleanliness'\n",
    "# #,'review_scores_checkin'\n",
    "# #,'review_scores_communication'\n",
    "# #,'review_scores_location'\n",
    "# #,'review_scores_value'\n",
    "# ,'email'\n",
    "# ,'phone'\n",
    "# ,'work_email'\n",
    "# ,'amenity_count'\n",
    "# ,'smoke_alarm'\n",
    "# #,'kitchen'\n",
    "# ,'essentials'\n",
    "# ,'hangers'\n",
    "# #,'wifi'\n",
    "# ,'source_previous scrape'\n",
    "# ,'host_is_superhost_t'\n",
    "# ,'host_has_profile_pic_t'\n",
    "# ,'host_identity_verified_t'\n",
    "# #,'has_availability_t'\n",
    "# ,'instant_bookable_t'\n",
    "# #,'property_type'\n",
    "# #,'neighbourhood_cleansed'\n",
    "# ,'log_price'\n",
    "\n",
    "# ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
