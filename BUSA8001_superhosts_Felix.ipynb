{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a106c2-f185-492f-87bb-79286c2eacc4",
   "metadata": {},
   "source": [
    "### Business Analytics Group Assignment - Predicting Airbnb Listing Prices in Melbourne__ {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c316658-edf7-4797-b078-202987b4922b",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Kaggle Competition Ends:** Friday, 2 June 2023 @ 3:00pm (Week 13)  \n",
    "**Assignment Due Date on iLearn:** Friday, 2 June 2023 @ 11.59pm (Week 13)   \n",
    "\n",
    "**Overview:**   \n",
    "\n",
    "- In the group assignment you will form a team of 3 students and participate in a forecasting competition on Kaggle\n",
    "- The goal is to predict listed prices of Airbnb properties in Melbourne based on various Airbnb characteristics and regression models\n",
    "- Assessment Summary:  \n",
    "    - Write a problem statement and perform Exploratory Data Analysis  \n",
    "    - Clean up data, deal with categorical features and missing observations, and create new explanatory variables (feature engineering)  \n",
    "    - Construct and tune forecasting models, produce forecasts and submit your predictions to Kaggle  \n",
    "    - Each member of the team will record a video presentation of their work  \n",
    "    - Marks will be awarded producing a prediction in the top 5 positions of their unit as well as for reaching the highest ranking on Kaggle amongst all teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2270744-5e12-447b-a861-9719409e287c",
   "metadata": {},
   "source": [
    "**Instructions:** \n",
    "\n",
    "- Form a team of 3 students (minimum 2 students)  \n",
    "- Each team member needs to join [https://www.kaggle.com](https://www.kaggle.com/)  \n",
    "- Choose a team leader and form a team in the competition [https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12](https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12)\n",
    "    - Team leader to click on `team` and join and invite other team members to join\n",
    "    - Your **team's name must start** with your unit code, for instance you could have a team called BUSA8001_masterful_geniuses or BUSA3020_l33t \n",
    "- All team members should work on all the tasks listed below however   \n",
    "    - Choose a team member who will be responsible for one of each of the 3 tasks listed below    \n",
    "- Your predictions must be generated by a model you develop here \n",
    "    - You will receive a mark of zero if your code provided here does not produce the forecasts you submit to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ee56b-c5b9-4078-8754-e04f90797514",
   "metadata": {},
   "source": [
    "**Marks**: \n",
    "\n",
    "- Total Marks: 40\n",
    "- Your individual mark will consist of:  \n",
    "    - 50% x overall assignment mark + 45% x mark for the task that you are responsible for + 5% x mark received from your teammates for your effort in group work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f70e4c-b794-4555-b170-d80b628b2904",
   "metadata": {},
   "source": [
    "**Competition Marks:**  \n",
    "\n",
    "- 1 mark: Ranking in the top 5 places of your unit on Kaggle (make sure you name your team as instructed above)   \n",
    "- 2 marks: Reaching the first place in your unit (make sure you name your team as instructed above)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3180e9-c3cc-494c-ae64-d3b9701e10e8",
   "metadata": {},
   "source": [
    "\n",
    "**Submissions:**  \n",
    "\n",
    "1. On Kaggle: submit your team's forecast in order to be ranked by Kaggle\n",
    "    - Can do this as many times as necessary while building their model  \n",
    "2. On iLearn **only team leader to submit** this Jupyter notebook re-named `Group_Assignment_Team_Name.ipynb` where Team_Name is your team's name on Kaggle   \n",
    "    - The Jupyter notebook must contain team members names/ID numbers, and team name in the competition\n",
    "    - Provide answers to the 3 Tasks below in the allocated cells including all codes/outputs/writeups \n",
    "    - One 15 minute video recording of your work \n",
    "        - Each team member to provide a 5 minute presentation of the Task that they led (it is best to jointly record your video using Zoom)\n",
    "        - When recording your video make sure your face is visible, that you share your Jupyter Notebook and explain everything you've done in the submitted Jupyter notebook on screen\n",
    "        - 5 marks will be deducted from each Task for which there is no video presentation or if you don't follow the above instructions\n",
    "        \n",
    "3. On iLearn each student needs to submit a file with their teammates' names, ID number and a mark for their group effort (out of 100%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbce8a-bf4f-4155-9336-6367fd239f6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe68a60-5e8b-4c4e-b562-3a82fa426395",
   "metadata": {},
   "source": [
    "**Fill out the following information**\n",
    "\n",
    "For each team member provide name, Student ID number and which task is performed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac487d3-755a-4a69-a22f-d599dbdd7979",
   "metadata": {},
   "source": [
    "- Team Name on Kaggle: `BUSA8001_superhosts`\n",
    "- Team Leader and Team Member 1: `Felix Rosenberger`\n",
    "- Team Member 2: `John Rizk`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24de689-928d-4991-b337-760c12780e5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Problem Description and Initial Data Analysis {-}\n",
    "\n",
    "1. Read the Competition Overview on Kaggle [https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12](https://www.kaggle.com/t/a154f28787174b628a2b7eaa238a5c12)\n",
    "2. Referring to Competition Overview and the data provided on Kaggle write about a 500 words **Problem Description** focusing on key points that will need to be addressed as first steps in Tasks 2 and 3 below, using the following headings:\n",
    "    - Forecasting Problem - explain what you are trying to do and how it could be used in the real world (i.e. why it may be important)\n",
    "    - Evaluation Criteria - explain the criteria is used to assess forecast performance \n",
    "    - Types of Variables/Features\n",
    "    - Data summary and main data characteristics\n",
    "    - Missing Values (only explain what you found at this stage)\n",
    "    - Hint: you should **not** discuss any specific predictive algorithms at this stage\n",
    "    - Note: This task should be completed in a single Markdown cell (text box)\n",
    "    \n",
    "Total Marks: 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e60aa0-5daa-4f83-ba4c-1f08cde3eee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfd49e-fcbb-4eaa-936b-144b574495d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 1 code here\n",
    "# setting display options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# read in data\n",
    "trainpath = \"train.csv\"\n",
    "train = pd.read_csv(trainpath)\n",
    "testpath = \"test.csv\"\n",
    "test = pd.read_csv(testpath)\n",
    "\n",
    "# concatenate dataframes to reduce redundancies in operations\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285f069-5d71-4475-b946-90933d85b868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# types of variables / features\n",
    "vtypes = df.dtypes.to_frame()\n",
    "#vtypes.value_counts()\n",
    "vtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9689eec-51dc-4c72-8dcc-59983bf3040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data summary and characteristics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3315c-f7d7-4cff-8715-b372d61e7d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missing values total\n",
    "total_miss = df.isna().sum()\n",
    "total_miss.to_frame()\n",
    "total_miss = total_miss.reset_index()\n",
    "total_miss.rename(columns={0:\"total\"}, inplace=True)\n",
    "#total_miss.loc[total_miss[\"total\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f1f25-19df-445e-a0f5-d2f44860dba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missing values train\n",
    "train_miss = train.isna().sum()\n",
    "train_miss.to_frame()\n",
    "train_miss = train_miss.reset_index()\n",
    "train_miss.rename(columns={0:\"train\"}, inplace=True)\n",
    "#train_miss.loc[train_miss[\"train\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4c00f-3137-490f-8457-cef4c6a68db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missing values test\n",
    "test_miss = test.isna().sum()\n",
    "test_miss.to_frame()\n",
    "test_miss = test_miss.reset_index()\n",
    "test_miss.rename(columns={0:\"test\"}, inplace=True)\n",
    "#test_miss.loc[test_miss[\"test\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0953130-f3b4-4624-b3aa-934783d0e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97ef04-e79c-4f83-a06c-11ff4f92aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6baa4f-f720-4327-9622-b06f3e6a79cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.columns[test.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93446f84-3d99-448b-8a2a-ac575b6d5c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_miss.set_index(\"index\", drop=True, inplace=True)\n",
    "test_miss.set_index(\"index\", drop=True, inplace=True)\n",
    "total_miss.set_index(\"index\", drop=True, inplace=True)\n",
    "train_miss.join([test_miss, total_miss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960bb55-92da-4528-9ee1-e06e46f00cae",
   "metadata": {},
   "source": [
    "`(Task 1, Text Here)`\n",
    "### Forecasting Problem\n",
    "The goal is to predict daily rental prices of Melbourne located AirBnB listings. This information could be used, for example, to assess the rental price a property with specific characteristics in certain suburbs is expected to yield. Especially in a business case scenario, where these cashflows might be used to pay off debt, this is a critical aspect for feasability assessment. In addition, people interested in building properties specifically for renting them on the platform would want to know which property characteristics lead to the highest prices and the analysis of the data reveals such patterns.\n",
    "\n",
    "### Evaluation Criteria\n",
    "The criteria to assess prediction performance is RMSE. This performance metric measures the average distance between predictions obtained by a model and actual target values. Thus, the lower the distance (and the smaller RMSE), the better the prediction quality. It also has the advantage of being in the same unit as the predicted variable which makes it easy to interpret.\n",
    "\n",
    "### Types of Variables / Features\n",
    "The 61 variables consist of various types which can be categorised as follows.\n",
    "#### Categorical\n",
    "##### Nominal\n",
    "source  \n",
    "name  \n",
    "description  \n",
    "neighborhood_overview  \n",
    "host_name  \n",
    "host_location  \n",
    "host_about  \n",
    "host_is_superhost  \n",
    "host_neighbourhood  \n",
    "host_verifications  \n",
    "host_has_profile_pic  \n",
    "host_identity_verified  \n",
    "neighbourhood  \n",
    "neighbourhood_cleansed  \n",
    "amenities  \n",
    "has_availability  \n",
    "number_of_reviews_l30d  \n",
    "instant_bookable  \n",
    "\n",
    "##### Ordinal\n",
    "host_response_time  \n",
    "property_type  \n",
    "room_type  \n",
    "\n",
    "\n",
    "#### Numerical\n",
    "ID  \n",
    "host_since  \n",
    "host_response_rate  \n",
    "host_acceptance_rate  \n",
    "host_listings_count  \n",
    "latitude  \n",
    "longitude  \n",
    "accommodates  \n",
    "bathrooms  \n",
    "bedrooms  \n",
    "beds  \n",
    "minimum_nights  \n",
    "maximum_nights  \n",
    "minimum_minimum_nights  \n",
    "maximum_minimum_nights  \n",
    "minimum_maximum_nights  \n",
    "maximum_maximum_nights  \n",
    "minimum_nights_avg_ntm  \n",
    "maximum_nights_avg_ntm  \n",
    "availability_30  \n",
    "availability_60  \n",
    "availability_90  \n",
    "availability_365  \n",
    "number_of_reviews  \n",
    "number_of_reviews_ltm  \n",
    "first_review  \n",
    "last_review  \n",
    "review_scores_rating  \n",
    "review_scores_accuracy  \n",
    "review_scores_cleanliness  \n",
    "review_scores_checkin  \n",
    "review_scores_communication  \n",
    "review_scores_location  \n",
    "review_scores_value  \n",
    "calculated_host_listings_count  \n",
    "calculated_host_listings_count_entire_homes  \n",
    "calculated_host_listings_count_private_rooms  \n",
    "calculated_host_listings_count_shared_rooms  \n",
    "reviews_per_month  \n",
    "price  \n",
    "\n",
    "### Data Summary and Main Data Characteristics\n",
    "This dataset contains all relevant information and characteristics of Airbnb listings.\n",
    "\n",
    "### Missing Values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30df24-b18b-4f61-975f-ceebe2e2c3ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Data Cleaning, Missing Observations and Feature Engineering {-}\n",
    "- In this task you will follow a set of instructions/questions listed below.\n",
    "- Make sure you **explain** each step you do both in Markdown text and on your video.\n",
    "    - Do not just read out your commands without explaining what they do and why you used them \n",
    "\n",
    "Total Marks: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4ec3d-4936-4428-a204-04f133210a3d",
   "metadata": {},
   "source": [
    "**Task 2, Question 1**: Clean **all** numerical features and the target variable `price` so that they can be used in training algorithms. For instance, `host_response_rate` feature is in object format containing both numerical values and text. Extract numerical values (or equivalently eliminate the text) so that the numerical values can be used as a regular feature.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32485e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 2, Question 1 Code Here\n",
    "# convert host response rate to decimal\n",
    "df.host_response_rate = df.host_response_rate.str.rstrip('%').astype('float') / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313fef0-4043-4c03-8f3f-4691b5f61f11",
   "metadata": {},
   "source": [
    "For the variable `host_response_rate`, the percentage values (which are in string format) are converted to decimals by stripping away the percentage sign and converting the value to a float subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02714bc3-daee-41af-8c56-671d6a925c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert host acceptance rate to decimal\n",
    "df.host_acceptance_rate = df.host_acceptance_rate.str.rstrip('%').astype('float') / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79c511-bfb6-4ee7-98e2-f26fb8a9ae6d",
   "metadata": {},
   "source": [
    "For the variable `host_acceptance_rate`, the percentage values (which are in string format) are converted to decimals by stripping away the percentage sign and converting the value to a float subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4dd5f8-6ab1-4e7c-94f2-866ade4e7a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove strings from bathroom variable\n",
    "df.bathrooms = pd.to_numeric(df.bathrooms.str.replace(r'[^0-9\\.]', ''), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544c3d2-19a6-4daa-b350-b71ffae85784",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the variable `bathrooms`, the values consist of a number and a string. Hence the strings are stripped away using regular expressions and the remaining values are converted to float. Because there were empty values which resulted in an error when converting to float, the errors parameter was used while converting to make sure these values would be set to NaN instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c81ee2-ccdc-4133-8d8e-cd664dbba3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove dollar sign from price\n",
    "df.price = df.price.str.replace('$', '', regex=True).str.replace(',', '', regex=True).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179f482-7c6a-40a7-8c44-56f679c8cb7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The variable `price` contained dollar signs and commas and was also not in numerical format. Hence these issues have been fixed using with the `str.replace` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f1bb1",
   "metadata": {},
   "source": [
    "**Task 2, Question 2** Create at least 4 new features from existing features which contain multiple items of information, e.g. creating `email`,  `phone`, `work_email`, etc. from feature `host_verifications`.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d210de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column sum of amenities\n",
    "#df8 = pd.read_csv(\"df_7.csv\")\n",
    "## convert column values to list\n",
    "#df8.amenities = df8.amenities.str.strip('][').str.replace('\"', '').str.split(', ')\n",
    "#\n",
    "## create new column with sum of items in each list\n",
    "#df8[\"sum_amenities\"] = df8.amenities.apply(lambda x: len(x))\n",
    "#\n",
    "#df8.drop(['amenities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c573e5-36ca-4f9d-8fe3-008299293cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df8.to_csv(\"df_8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fde9b6-bed0-4018-9edb-3553f3d1fa13",
   "metadata": {},
   "source": [
    "`(Task 2, Question 2 Text Here)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01c4d-1412-4e51-8f80-7040f536b1c7",
   "metadata": {},
   "source": [
    "**Task 2, Question 3**: Impute missing values for all features in both training and test datasets. Hint: make sure you do **not** impute the price in the test dataset.\n",
    "(3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36412d68-f68f-4764-aa6f-88ba33116ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 3 Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb16b1d-f4f1-438e-a5af-ae9cc3c04467",
   "metadata": {},
   "source": [
    "`(Task 2, Question 3 Text Here)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c14ab6-aff9-4fcd-ab7b-34f0b77f8caa",
   "metadata": {},
   "source": [
    "**Task 2, Question 4**: Encode all categorical variables appropriately as discussed in class. \n",
    "\n",
    "\n",
    "Where a categorical feature contains more than 5 unique values, map the feature into 5 most frequent values + 'other' and then encode appropriately. For instance, you could group then map `property_type` into 5 most frequent property types + 'other'  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f4448-8574-4397-a636-d83bbde885e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 4 Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad3f20-7549-4b9e-8894-818c976d1457",
   "metadata": {},
   "source": [
    "`(Task 2, Question 4 Text Here)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d695347",
   "metadata": {},
   "source": [
    "**Task 2, Question 5**: Perform any other actions you think need to be done on the data before constructing predictive models, and clearly explain what you have done.   \n",
    "(1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a238a3-5432-4058-8b6e-1172c4e396ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f8067-9723-4f39-ac09-14b78dd48e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "823a081c-cdc4-4fc8-9bd7-52bfd4c3e6dd",
   "metadata": {},
   "source": [
    "`(Task 2, Question 5 Text Here)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16475c",
   "metadata": {},
   "source": [
    "**Task 2, Question 6**: Perform exploratory data analysis to measure the relationship between the features and the target and write up your findings. \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.read_csv(\"df_7.csv\")\n",
    "df9.drop([\"latitude\", \"longitude\", \"source_previous scrape\"], axis=1, inplace=True)\n",
    "df9.to_csv(\"df_9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d063c17-71f4-47ff-b988-2b0a0dd27911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05396c-6aa9-4321-ae24-ce0af57d0ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e324c6b-13a0-40a0-bcb7-aa0505eeabd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099e296-48fe-4dd1-8ee8-6b33c4b0b77d",
   "metadata": {},
   "source": [
    "#### Univariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270ee6c-abcd-462a-a21d-13d36ed3d167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[['host_since', 'host_response_rate',\n",
    "       'host_acceptance_rate', 'host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'minimum_nights',\n",
    "       'maximum_nights', #'availability_30', 'availability_60',\n",
    "       #'availability_90', 'availability_365', \n",
    "     'review_scores_rating', 'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     'log_price',\n",
    "       'amenity_count']].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f04da4-5481-4a6e-91f6-5f8d7b002d90",
   "metadata": {},
   "source": [
    "price heavily influences the overall picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9769a-982b-4e19-967b-3e33275453fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[['host_since', 'host_response_rate',\n",
    "       'host_acceptance_rate', 'host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'minimum_nights',\n",
    "       'maximum_nights', #'availability_30', 'availability_60',\n",
    "       #'availability_90', 'availability_365', \n",
    "     'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     'log_price',\n",
    "       'amenity_count']].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba3ccb-fe9c-46d5-9f67-944b5741e1bb",
   "metadata": {},
   "source": [
    "Still a few distortions, let's look at the variables with large magnitude only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d310c6-afad-493b-8aad-c3f33cd48e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[['host_since', #'host_response_rate',\n",
    "       #'host_acceptance_rate', 'host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "     'minimum_nights', 'maximum_nights', #'availability_30', 'availability_60',\n",
    "       #'availability_90', 'availability_365', \n",
    "     #'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     #'log_price', 'amenity_count'\n",
    "    ]].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630f9c5-3e1b-4b6d-99eb-e070be731397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', #'host_response_rate',\n",
    "       #'host_acceptance_rate', 'host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "     'minimum_nights', 'maximum_nights', #'availability_30', 'availability_60',\n",
    "       #'availability_90', 'availability_365', \n",
    "     #'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     #'log_price', 'amenity_count'\n",
    "    ]].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb55435-8afa-4f1e-bf1a-d1f6a02c1eed",
   "metadata": {},
   "source": [
    "It is clear that there a few listings which have extremely large minimum nights restrictions. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5637c-da13-4b70-80ff-6aca830c85d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.loc[df9.minimum_nights > 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc5cc3-32d3-4bf8-8413-3a6b11365f8f",
   "metadata": {},
   "source": [
    "Now let's look at variables with lower magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d76b2-9c48-4ac2-b3e3-facdbaa2ad80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    'host_response_rate', 'host_acceptance_rate', #'host_listings_count', \n",
    "    'accommodates', 'bathrooms', 'bedrooms', 'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       'property_type', 'neighbourhood_cleansed', \n",
    "     'log_price',\n",
    "       'amenity_count']].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbca975-7aed-4136-a27b-e8dc0e0ebca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    'host_response_rate', 'host_acceptance_rate', #'host_listings_count', \n",
    "    'accommodates', 'bathrooms', 'bedrooms', 'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       'property_type', 'neighbourhood_cleansed', \n",
    "     'log_price',\n",
    "       #'amenity_count'\n",
    "]].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f878be2-7ff0-42bc-a07b-ff18aab87140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    'host_response_rate', #'host_acceptance_rate', #'host_listings_count', \n",
    "    #'accommodates', 'bathrooms', 'bedrooms', 'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     #'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "      # 'property_type', 'neighbourhood_cleansed', \n",
    "     #'log_price',\n",
    "       #'amenity_count'\n",
    "]].plot.box(vert = False, grid = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a383575-9619-4ea6-bf28-ae88ff459454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.loc[df9.host_response_rate < 0.2].price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617a946-b3db-466b-a26d-c30014706a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.loc[df9.host_response_rate >= 0.2].price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4976285-de27-436f-b430-79783e4597d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    #'host_response_rate', 'host_acceptance_rate', #'host_listings_count', \n",
    "    'accommodates', #'bathrooms', 'bedrooms', 'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     'log_price',\n",
    "       #'amenity_count'\n",
    "]].plot.density();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79cd288-1486-45fe-bf56-3eba6043ca3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    #'host_response_rate', 'host_acceptance_rate', #'host_listings_count', \n",
    "    #'accommodates', \n",
    "    'bathrooms', #'bedrooms', 'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     #'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     #'log_price',\n",
    "       #'amenity_count'\n",
    "]].plot.density();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2f021-24c6-4fa5-bd5e-0936586c1a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    #'host_response_rate', 'host_acceptance_rate', #'host_listings_count', \n",
    "    #'accommodates', \n",
    "    #'bathrooms', \n",
    "    'bedrooms', #'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     #'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     #'log_price',\n",
    "       #'amenity_count'\n",
    "]].plot.density();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624990fe-fc05-4284-9a3a-d5a017268e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9[[#'host_since', \n",
    "    #'host_response_rate', 'host_acceptance_rate', #'host_listings_count', \n",
    "    #'accommodates', \n",
    "    #'bathrooms', \n",
    "    #'bedrooms', \n",
    "    'beds', #'minimum_nights',\n",
    "       #'maximum_nights', \n",
    "    #'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "     #'review_scores_rating', #'price',\n",
    "       #'email', 'phone', 'work_email', 'smoke_alarm', 'kitchen', 'essentials', 'hangers', 'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       #'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       #'property_type', 'neighbourhood_cleansed', \n",
    "     #'log_price',\n",
    "       #'amenity_count'\n",
    "]].plot.density();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d779c06-9559-4fed-9221-0772314516ca",
   "metadata": {},
   "source": [
    "#### Bivariate EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d0d27-e9b1-48c3-b129-b58128389b9c",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd716832-4d66-4266-9319-ef9d70e70b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = df9[['host_since', 'host_response_time', 'host_response_rate',\n",
    "       'host_acceptance_rate', 'host_listings_count', 'room_type',\n",
    "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'minimum_nights',\n",
    "       'maximum_nights', 'availability_30', 'availability_60',\n",
    "       'availability_90', 'availability_365', 'number_of_reviews',\n",
    "       'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "       'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value', 'email', 'phone', 'work_email',\n",
    "       'amenity_count', 'smoke_alarm', 'kitchen', 'essentials', 'hangers',\n",
    "       'wifi', 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "       'host_identity_verified_t', 'has_availability_t', 'instant_bookable_t',\n",
    "       'property_type', 'neighbourhood_cleansed', 'price', 'log_price']].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4cbc2-c9b6-471d-9612-6c39515886fc",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "`host_since, host_response_time, host_response_rate, host_acceptance_rate, and host_listings_count`\\\n",
    "do not seem related to any other variables. Likely that they should be dropped.\\\n",
    "`Room Type`\\\n",
    "negative correlation of -0.49 with log price --> larger rooms are encoded with smaller integers. Hence correlation indicates that large / more private room types correlate with higher prices. Interestingly the relationship becomes irrelevant for non-log prices.\\\n",
    "`accommodates, bathrooms, bedrooms, beds`\\\n",
    "very strong correlation. This has to be analysed further to avoid multicollinearity down the line. accommodates and bedrooms have strongest positive correlation with log price out of those four.\\\n",
    "`minimum_nights and maximum_nights`\\\n",
    "do not seem related to any other variables. Likely that they should be dropped.\\\n",
    "`availability_30, availability_60, availability_90, and availability_365`\\\n",
    "There seems to be some relation with log price. Out of those, availability_30 seems to have strongest relation. Others should likely be dropped due to multicollinearity.\\\n",
    "`review_scores_rating, email, phone, work_email, smoke_alarm, kitchen, essentials, hangers, wifi, host_is_superhost_t, host_has_profile_pic_t, host_identity_verified_t, and has_availability_t`\\\n",
    "These seem all unrelated to both log price and price.\\\n",
    "`instant_bookable_t, property_type, neighbourhood_cleansed, and sum_amenities`\\\n",
    "These seem to have weak but existent relationship with log prices. instant_bookable and sum_amenities are positively related while property_type and neighbourhood_cleansed have a negative relationship. Thus, for property types the same logic applies as for room types and they might capture similar information. In the case of neighbourhood_cleansed it implies that the more listings exist in a suburb in the data, the higher its prices seem to be. Even though this is probably a weak relationship, but due to the construction of the neighbourhood encoding it seems to be the case. Further analysis is required with respect to individual suburbs as predictors of price.\n",
    "\n",
    "NOTE: All correlations of prices with categorical data should be taken cautiously as the pearson correlation coefficient might not be suitable for those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d1ae8-2d8e-48e1-b9f8-f2fc41ec2b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 15))\n",
    "# Plotting the heatmap with respect to the correlation of the features with the target variable\n",
    "sns.heatmap(df9.corr()[['log_price']].sort_values(by='log_price', ascending=False), annot=True, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ccf06-a939-4258-82c8-d7fe24572b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#continuous_features = [col for col in data.columns if data[col].dtype != 'O']\n",
    "#for col in continuous_features:\n",
    "#      data_copy = data.copy()\n",
    "#      if 0 in data_copy[col].unique():\n",
    "#            pass\n",
    "#       else:\n",
    "#            data_copy[col] = np.log(data_copy[col])\n",
    "#            data_copy['SalePrice'] = np.log(data_copy['SalePrice'])\n",
    "#            plt.scatter(data_copy[col], data_copy['SalePrice'])\n",
    "#            plt.xlabel(col)\n",
    "#            plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739844a0-56bf-4658-b887-b25f9cbb7d39",
   "metadata": {},
   "source": [
    "##### Price vs Room Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e38d5-658b-4320-aceb-52eb8ab41e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.groupby('room_type').price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f44c7-4035-4195-9bb9-97b57e687e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=\"room_type\", y=\"price\", data=df9, hue=\"room_type\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0a6a0-7fa6-4fdb-be3f-2b2ba5dba903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"room_type\", y=\"price\", data=df9.loc[df9.price < 5000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74391102-5aa7-400b-b77b-1e3990eb0288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"room_type\", y=\"price\", data=df9, hue=\"room_type\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58695fd5-acf2-407e-92c3-6512381e03ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a08115-8a62-4b5a-960f-f5a4a94965be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = df9.iloc[0:7000,]\n",
    "test = df9.iloc[7000:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf34157-a427-4ba9-8a80-6af653f61fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train.room_type.value_counts(normalize=True))\n",
    "print(test.room_type.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d5f88a-02a6-4c60-88c4-ec30a0a555d1",
   "metadata": {},
   "source": [
    "For room type 0 and 2 there seem to be a few outliers that skew the results of the mean prices in these groups. Also room types 1 and 3 are heavily underrepresented in the data across both training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bbfcc-e82c-48ce-a8cc-6c988b508b5e",
   "metadata": {},
   "source": [
    "##### Price vs accommodates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b3172-fe95-4038-b223-b4f188ae519e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.groupby('accommodates').price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc7233-5657-4bfb-b7dc-2769197394b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"accommodates\", y=\"price\", data=df9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc49ce5-0c71-41a3-bc73-cfea30c520cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"accommodates\", y=\"price\", data=df9.loc[df9.price < 5000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15694643-2a49-4446-8761-418a2aa511d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"accommodates\", y=\"price\", data=df9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f826268-0c2c-4243-8a72-e397f2e714ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.accommodates.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41d12f-c8be-4d5b-b0b0-8e8e7ebf2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train.accommodates.value_counts(normalize=True))\n",
    "print(test.accommodates.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bd054-2536-4520-8c51-eb98331472d9",
   "metadata": {},
   "source": [
    "##### Price vs Bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7b3ac-5c64-4300-b13b-04134102ac4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.groupby('bathrooms').price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746340f0-1bfc-411f-a839-1a147fbb49ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"bathrooms\", y=\"price\", data=df9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127234e9-b313-44fc-a9d7-a422ff325550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"bathrooms\", y=\"price\", data=df9.loc[df9.price < 5000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f61b9-56c6-4b08-a111-cae9449ca4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.loc[df9.price > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05320d3-a859-4dce-80d1-712d4783c5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.bathrooms.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f50b7-bc03-4a0d-bc46-fed4fb74b378",
   "metadata": {},
   "source": [
    "##### Price vs Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a6014-f787-4446-9757-f9432df5f1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.groupby('bedrooms').price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec041af-d216-4f82-b127-7a41f951c370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"bedrooms\", y=\"price\", data=df9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af0121-34a6-4885-905a-c5d3f767835e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"bedrooms\", y=\"price\", data=df9.loc[df9.price < 5000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188060bb-79c7-49e4-85d0-da69c0437b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"bedrooms\", y=\"price\", data=df9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6980613-a247-452a-89cc-26cd8b832858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.bedrooms.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b48b2-6229-4673-9193-b60d984883c0",
   "metadata": {},
   "source": [
    "##### Price vs availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6572d3-c52b-4709-baf2-b6b2b57a9b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"availability_30\", y=\"price\", data=df9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed71821-97c0-45db-8438-9a7b5c0d89f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"availability_30\", y=\"price\", data=df9.loc[df9.price < 5000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44767735-e334-47cf-9c16-6e1bc14a1e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140c516-4fc8-4582-ade6-ba919ee450a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d4ac4-924b-41b7-ba55-e15b8e7daa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "031d0504-9dea-4d66-aadd-f330827e0e5c",
   "metadata": {},
   "source": [
    "##### Price vs sum_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d0281-9574-432f-ad81-4f3fdc1f3197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"amenity_count\", y=\"price\", data=df9.loc[df9.price < 5000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51374ab2-50c4-4932-8537-057b000e0b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d2cfc-c74d-436a-9646-4fe6b9156957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998231e6-19af-4d5f-a0c4-cb7ea2e0a9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c1dd5-ef54-40af-8082-cc5a44523493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a1d7b-47db-49f1-a429-433867414581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60dd65-9e78-4ceb-b7ab-b86fb2ed5535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2fc70-bef0-4ad5-8a5d-7bfeeac69f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaecc08f-dc7c-4ccd-a37c-625a120c23d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9aca65-59c0-4395-93d8-e4b3735ba49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a965eb-e661-4772-af72-98f19e1bae41",
   "metadata": {},
   "source": [
    "`(Task 2, Question 6 Text Here)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f6968-d9c2-422f-9935-eba856b3c028",
   "metadata": {},
   "source": [
    "--- \n",
    "## Task 3: Fit and tune a forecasting model/Submit predictions/Report score and ranking {-}\n",
    "\n",
    "Make sure you **clearly explain each step** you do, both in text and on the recoded video.\n",
    "\n",
    "1. Build a machine learning (ML) regression model by taking into account the outcomes of Tasks 1 & 2 (Explain carefully)\n",
    "2. Fit the model and tune hyperparameters via cross-validation: make sure you comment and explain each step clearly\n",
    "3. Create predictions using the test dataset and submit your predictions on Kaggle's competition page\n",
    "4. Provide Kaggle ranking and **score** (screenshot your best submission) and Comment\n",
    "5. Make sure your Python code works, so that a marker that can replicate your all of your results and obtain the same RMSE from Kaggle\n",
    "\n",
    "- Hint: to perform well in this assignment you will need to iterate Tasks 2 & 3, creating new features and training various models in order to find the best one.\n",
    "\n",
    "Total Marks: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882f29a6-a86e-41cd-823f-040325012189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9 = pd.read_csv(\"df_9.csv\")\n",
    "test_ids = df9.ID.iloc[7000:].values # save IDs for later output\n",
    "df9.drop([\"Unnamed: 0\", \"ID\", 'price', 'host_has_profile_pic_t','host_identity_verified_t'], axis=1, inplace=True)\n",
    "y_train = df9['log_price'].iloc[:7000].values\n",
    "#y_test = np.zeros(3000)\n",
    "X_train = df9.drop(['log_price'], axis=1).iloc[:7000].values\n",
    "X_test = df9.drop(['log_price'], axis=1).iloc[7000:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe46b90-6b78-4c16-b21f-3c4038866d75",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53af94-d769-4a1d-a4a1-433f3dc7b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9 = df9.head(7000)\n",
    "#y = df9['log_price'].values.ravel()\n",
    "#ts = 0.30; rs = 10\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = ts, random_state = rs, stratify=None)\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "n_folds = 10\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = -cross_val_score(pipe_rf, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "mse = np.mean(cv_scores)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"CV Root Mean Squared Error:\", rmse)\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipe_rf.predict(X_test)\n",
    "y_pred_dollar = np.exp(y_pred)\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#rmse = np.sqrt(mse)\n",
    "#print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# calculate RMSE in original scale\n",
    "#y_pred_dollar = np.exp(y_pred)\n",
    "#y_test_dollar = np.exp(y_test)\n",
    "#\n",
    "#rmse = np.sqrt(mean_squared_error(y_test_dollar, y_pred_dollar))\n",
    "#print(f'Root Mean Squared Error in AUD: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571f371-005f-49aa-b90d-9451f71322dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ts = 0.30; rs = 10\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = ts, random_state = rs, stratify=None)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "pipe_rf = make_pipeline(RandomForestRegressor(random_state=42))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "n_folds = 20\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = -cross_val_score(pipe_rf, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "mse = np.mean(cv_scores)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"CV Root Mean Squared Error:\", rmse)\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipe_rf.predict(X_test)\n",
    "y_pred_dollar = np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026013c-0a52-457d-ab11-2666cbf71180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c892930-4ccc-41c7-9068-b16e1d89bd01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333e012-20d6-4f13-9b22-332d9ac1f7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save predictions to csv\n",
    "out = pd.DataFrame({\"ID\":test_ids, \"price\":y_pred_dollar})\n",
    "out.to_csv(\"RandomForestPredictions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acdc7f-95cc-4d9f-b751-86e2b3b8fab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf582b79-81ae-4b14-87dd-b5d606b8305d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9.iloc[7000:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ca0b9-f2d0-4039-9dd8-3b14c9e012c6",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeabbdc-8fe4-458f-b005-9bb2fe381702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa462f03-c768-48af-af02-592a3a9a9460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# first let's do randomized grid search to narrow down parameter ranges\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 100)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [1.0, 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(1, 20, num = 10)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# sample size per bootstrap sample\n",
    "max_samples = [x for x in np.linspace(0.1, 1, num = 10)]\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
    "               'randomforestregressor__max_features': max_features,\n",
    "               'randomforestregressor__max_depth': max_depth,\n",
    "               'randomforestregressor__min_samples_split': min_samples_split,\n",
    "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestregressor__bootstrap': bootstrap,\n",
    "               'randomforestregressor__max_samples': max_samples}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9144cb5-e1ae-4c2e-80b3-c1dec3ce9113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "\n",
    "gs_random = RandomizedSearchCV(estimator = pipe, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 10,  \n",
    "                               n_jobs = -1,\n",
    "                               scoring = 'neg_mean_squared_error')\n",
    "# Fit the random search model\n",
    "gs_random.fit(X_train, y_train)\n",
    "print(gs_random.best_estimator_)\n",
    "print(gs_random.best_params_)\n",
    "print(gs_random.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f9c1e-a221-4923-9c50-af390713ac9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# narrow down optimal parameter values\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforestregressor__bootstrap': [True],\n",
    "    'randomforestregressor__max_depth': [50, 55],\n",
    "    'randomforestregressor__max_features': [0.9, 1.0],\n",
    "    'randomforestregressor__max_samples': [0.85, 0.9],\n",
    "    'randomforestregressor__min_samples_leaf': [2, 3],\n",
    "    'randomforestregressor__min_samples_split': [6, 8],\n",
    "    'randomforestregressor__n_estimators': [1300, 1400]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1,\n",
    "                           scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f764e1-4e1c-4eff-ac3b-f5a302b6f7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# narrow down parameter values again\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforestregressor__bootstrap': [True],\n",
    "    'randomforestregressor__max_depth': [45, 50],\n",
    "    'randomforestregressor__max_features': [0.85, 0.90],\n",
    "    'randomforestregressor__max_samples': [0.80, 0.85],\n",
    "    'randomforestregressor__min_samples_leaf': [3, 4],\n",
    "    'randomforestregressor__min_samples_split': [5, 6],\n",
    "    'randomforestregressor__n_estimators': [1400, 1500]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1,\n",
    "                           scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc935ccc-3d32-4b54-94db-91672d2d935a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# narrow down parameter values again\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforestregressor__bootstrap': [True],\n",
    "    'randomforestregressor__max_depth': [35, 40, 45],\n",
    "    'randomforestregressor__max_features': [0.75, 0.80, 0.85],\n",
    "    'randomforestregressor__max_samples': [0.85],\n",
    "    'randomforestregressor__min_samples_leaf': [3],\n",
    "    'randomforestregressor__min_samples_split': [4, 5],\n",
    "    'randomforestregressor__n_estimators': [1400]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1,\n",
    "                           scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5d6d9-37bd-4d3b-835b-cb9e3e3ab7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# narrow down parameter values again\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforestregressor__bootstrap': [True],\n",
    "    'randomforestregressor__max_depth': [25, 30, 35],\n",
    "    'randomforestregressor__max_features': [0.65, 0.70, 0.75],\n",
    "    'randomforestregressor__max_samples': [0.85],\n",
    "    'randomforestregressor__min_samples_leaf': [3],\n",
    "    'randomforestregressor__min_samples_split': [3, 4],\n",
    "    'randomforestregressor__n_estimators': [1400]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1,\n",
    "                           scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ae560-25cb-4b31-b367-634fbb3876d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# narrow down parameter values again\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforestregressor__bootstrap': [True],\n",
    "    'randomforestregressor__max_depth': [15, 20, 25],\n",
    "    'randomforestregressor__max_features': [0.55, 0.60, 0.65],\n",
    "    'randomforestregressor__max_samples': [0.85],\n",
    "    'randomforestregressor__min_samples_leaf': [3],\n",
    "    'randomforestregressor__min_samples_split': [2, 3],\n",
    "    'randomforestregressor__n_estimators': [1400]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1,\n",
    "                           scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ad1fc5-ae2c-429a-8225-07d0a0027f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=25, max_features=0.45,\n",
      "                                       max_samples=0.85, min_samples_leaf=3,\n",
      "                                       min_samples_split=3, n_estimators=1400,\n",
      "                                       random_state=42))])\n",
      "{'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 25, 'randomforestregressor__max_features': 0.45, 'randomforestregressor__max_samples': 0.85, 'randomforestregressor__min_samples_leaf': 3, 'randomforestregressor__min_samples_split': 3, 'randomforestregressor__n_estimators': 1400}\n"
     ]
    }
   ],
   "source": [
    "# narrow down parameter values again\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforestregressor__bootstrap': [True],\n",
    "    'randomforestregressor__max_depth': [25],\n",
    "    'randomforestregressor__max_features': [0.40, 0.45, 0.50, 0.55],\n",
    "    'randomforestregressor__max_samples': [0.85],\n",
    "    'randomforestregressor__min_samples_leaf': [3],\n",
    "    'randomforestregressor__min_samples_split': [3],\n",
    "    'randomforestregressor__n_estimators': [1400]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1,\n",
    "                           scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925a0e53-57da-42ca-8059-3cdaebfca428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Root Mean Squared Error: 0.39845366662536064\n"
     ]
    }
   ],
   "source": [
    "# final model\n",
    "pipe_rf = make_pipeline(RandomForestRegressor(random_state=42,\n",
    "                                             max_depth=25, max_features=0.45,\n",
    "                                             max_samples=0.85, min_samples_leaf=3,\n",
    "                                             min_samples_split=3, n_estimators=1400,\n",
    "                                             bootstrap=True))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "n_folds = 20\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = -cross_val_score(pipe_rf, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "mse = np.mean(cv_scores)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"CV Root Mean Squared Error:\", rmse)\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipe_rf.predict(X_test)\n",
    "y_pred_dollar = np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3058a78f-8b38-47ef-9f1f-1ecf328e219b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save predictions to csv\n",
    "out = pd.DataFrame({\"ID\":test_ids, \"price\":y_pred_dollar})\n",
    "out.to_csv(\"RandomForestPredictions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da9ef8-6c4b-4ae6-ab48-2de05e1fedeb",
   "metadata": {},
   "source": [
    "#### ExtraTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeee663-8207-4dc4-a99a-ffb26f919781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dea63c-b848-4ce7-8a79-39987c3f4e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7fcb2-26cc-4a21-80a8-333dab2c8958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a9ed3-876c-4d3a-a35d-5ec469d51f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723e446-4065-4455-8e89-4ea35a758974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a1010e5-03e6-475b-a9f8-51b19cb556d2",
   "metadata": {},
   "source": [
    "`(Task 3 - insert more cells as required)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
